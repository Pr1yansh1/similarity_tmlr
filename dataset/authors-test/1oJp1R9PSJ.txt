Under review as submission to TMLR
Evaluating the Evaluators: Which UDA validation methods
are most effective? Can they be improved?
Anonymous authors
Paper under double-blind review
Abstract
This paper compares and ranks 8 UDA validation methods. Validators estimate model
accuracy, which makes them an essential component of any UDA train-test pipeline. We
rank these validators to indicate which of them are most useful for the purpose of selecting
optimal model checkpoints and hyperparameters. To the best of our knowledge, this large-
scale benchmark study is the first of its kind in the UDA field. In addition, we propose 3
new validators that outperform existing validators. When paired with one particular UDA
algorithm, one of our new validators achieves state-of-the-art performance.
1 Introduction
Unsupervised domain adaptation (UDA) is a machine-learning technique for training models. It allows the
categorization of unlabeled target-data by a model that is trained on labeled source-data. To date, much
UDA research has been focused on the algorithms that train models. This paper focuses instead on validation
methods, also known as validators.
Validators generate validation scores, to estimate the accuracy of a model in categorizing unlabeled data.
Validation scores are needed because, in the absence of labels, it is impossible to directly compute model
accuracy in the target domain. However, model accuracy and validation scores are not always highly correlated.
A poor validator can yield misleading estimates of model accuracy, resulting in the selection of sub-optimal
model checkpoints and hyperparameters. To avoid this, researchers and engineers need to use validators that
are the most reliable at estimating model accuracy.
Existing papers evaluate validators on checkpoint sets that are too small and homogeneous to accurately
reveal which validators are most reliable. That is why this large-scale benchmark is needed. In this paper, we
compare the effectiveness of 8 UDA validation methods on a large dataset of checkpoints generated by a
variety of UDA algorithms and hyperparameter settings.
We consider the following questions:
1.Which validation methods generate validation scores that are highly correlated with model accuracy?
In other words, which validators provide the most reliable guidance for researchers and engineers
who need to select optimal model checkpoints and hyperparameters?
2. Can some existing validators be improved to yield more reliable estimates of model accuracy?
In summary, in this paper we have:
•Benchmarked and ranked 8 validators on a large dataset of 760,000 checkpoints generated by 10
UDA algorithms and 100 hyperparameter settings per algorithm.
•Significantly improved 2 existing validators.
•Developed a new validator that, when paired with an existing algorithm, achieves state-of-the-art
performance.
1Under review as submission to TMLR
The paper is organized as follows:
•Sections 1.1 and 1.2 provide an overview of existing validation methods, and the 3 new validation
methods that we propose.
•Section 2 explains our experiment methodology.
•Section 3 shows which validators are most effective.
•The Appendix provides additional explanations, experiment details, tables of results, and an overview
of UDA algorithms.
1.1 Existing validation methods
Source accuracy
This is simply the model’s accuracy on the source domain:
Accuracy =1
NN/summationdisplay
i=11(arg max(pi) =yi) (1)
where 1is the indicator function, Nis the size of the source dataset, piis theith prediction vector, and yiis
the label for the ith dataset sample. The assumption here is that the source and target domains are similar
enough that high source-accuracy implies high target-accuracy.
Reverse validation (Zhong et al., 2010; Ganin et al., 2016)
This method consists of two steps. First it trains a model via UDA on the source ( S) and target ( T) data,
and uses this model to create pseudo-labels for T. Next, it trains a reverse model via UDA on TandS, where
Tis the pseudo-labeled target data, and Sis the “unlabeled” source data. The final score is the accuracy
of the reverse model on S. One disadvantage of this approach is that it trains two models, doubling the
required training time, but still producing only a single usable model. Furthermore, all it does is make it
easier to choose between training runs (i.e. for tuning hyperparameters). So selecting the best forward-model
checkpoint requires using another validator that can compute scores per checkpoint.
Entropy
This measures the “confidence” of the model:
Entropy =1
NN/summationdisplay
i=1H(pi) (2)
H(pi) =−C/summationdisplay
j=1pijlogpij (3)
whereH(pi)is the entropy of the ith prediction vector, Cis the number of classes, and Nis the size of the
target dataset. An accurate model will output prediction vectors that have a single large value corresponding
with the correct class for each sample. This produces a low entropy score, indicating high confidence. However,
this method fails if a model is incorrectly confident. For example, the model might incorrectly classify all
samples in the dataset as belonging to the same class.
2Under review as submission to TMLR
Deep embedded validation (DEV) (You et al., 2019b)
This computes a classification loss for every source validation sample, and weights each loss based on the
probability that the sample belongs to the target domain. The probability comes from a domain classifier
trained on source and target data.
DEV=mean (L) +ηmean (W)−η (4)
η=Cov(L,W )
Var(W)(5)
whereLis the source validation losses, and Wis the weight of each loss. One practical issue with DEV is
that its scores are unbounded. Very large values can occur if Whas low variance, or if LandWhave high
covariance.
Proxy risk (Chuang et al., 2020)
This method evaluates checkpoints using a “check” model. The check model predicts both class label and
domain, and is trained on the transfer task using an algorithm such as DANN (Ganin et al., 2016), with an
additional “disagreement” loss term on the target samples:
D=1
BB/summationdisplay
i=1−||xi−mi||2 (6)
whereBis the batch size, xiandmiare theith prediction vector of the checkpoint and the check model
respectively, and ||.||2is the L2 norm function. If the check model maintains a low DANN loss, but obtains
outputs that differ from the checkpoint, then the checkpoint likely has low accuracy on the target domain. The
disadvantage of this method is that it requires training a DANN-like model for every checkpoint, increasing
total training time from O(epochs ), toO(epochs2).
Ensemble-based model selection (EMS) (Robbiano et al., 2021)
This uses a linear regressor trained on 5 signals: target entropy, target diversity, silhoutte & Calinski-Harabasz
scores on the target features, source accuracy, and time-consistent pseudo-labels. EMS differs from other
methods because it requires a dataset of {signal, ground truth accuracy} pairs to train the regressor. These
pairs have to be collected by training a model on a domain adaptation task that has labeled target data. A
drawback of this method is that the regressor may overfit and not generalize to our actual UDA task.
Soft neighborhood density (SND) (Saito et al., 2021)
This computes the entropy of the softmaxed target similarity matrix:
SND=H(softmaxτ(/hatwideX)) (7)
X=FTF (8)
whereHis the entropy function, softmaxτis the softmax function with temperature τ,Xis the similarity
matrix,Fis the set of L2 normalized target feature vectors, and /hatwideXisXwith the diagonal entries removed.
A high SND score means that each feature is close to many other features, which can indicate good clustering.
The caveat of SND is that it assumes the model has not mapped all target features into a single cluster. A
single cluster would result in a high SND score, but low accuracy.
1.2 New validation methods
Here we explain our proposed validators, which include modifications of existing methods.
3Under review as submission to TMLR
Batch nuclear-norm maximization (BNM) (Cui et al., 2020a)
BNM is a UDA algorithm which aims to generate predictions that are both diverse and confident. It
approaches this via singular value decomposition:
BNM=||P||∗ (9)
wherePis theN×Cprediction matrix ( Nis the dataset size and Cis the number of classes), and ||P||∗
is the nuclear norm (the sum of the singular values) of P. This simple loss function is highly effective at
training UDA models, which leads us to wonder if its numerical value is a proxy for target domain accuracy.
We propose using BNM as a validator by applying the BNM loss function to all of the prediction vectors of
the source and/or target domain. A drawback of BNM is that the computation can be expensive for large
datasets with many classes, though fast approximations do exist (Cui et al., 2021).
ClassAMI
Robbiano et al. (2021) proposed using the silhouette score of the target features clustered with k-means (we
call this “ClassSS”). However, the silhouette score rewards tightly-bound clusters that are far apart from
each other, which is not strictly necessary for high accuracy. We propose replacing the silhouette score with a
less stringent, but more direct approach: the Adjusted Mutual Information (AMI) between cluster labels and
the predicted target labels.
ClassAMI =AMI(X,kmeans (F).labels ) (10)
Xi= arg maxpi (11)
whereXis the predicted labels for the target data, piis theith prediction vector, and Fis the set of target
features.
DEV with normalization (DEVN)
One practical concern with DEV is that ηcan become very large if Whas low variance, or if LandW
have high covariance. To avoid this, we propose normalizing the weights by either max normalization or
standardization.
Max normalization:
weights /= max(weights) # normalize between 0 and 1
weights -= mean(weights) - 1 # shift to have mean of 1
Standardization:
weights = (weights - mean(weights)) / std(weights) # standardize
weights += 1 # shift to have mean of 1
1.3 How the new and existing validators are related
Table 1: How our proposed validators relate to existing validators and UDA algorithms.
Existing validator or algorithm Our proposed validator
BNM (used as an algorithm) BNM (used as a validator)
ClassSS (validator) ClassAMI
DEV (validator) DEVN
4Under review as submission to TMLR
2 Experiment Methodology
To allow for efficient benchmarking, we created a dataset of feature vectors that could be easily loaded and
used as input to all validation methods.
2.1 Creating the dataset of feature vectors
We ran experiments on 19 transfer tasks:
•MNIST : 1 task between MNIST and MNISTM (Ganin et al., 2016).
•Office31 (Saenko et al., 2010): 6 tasks between 3 domains (Amazon, DSLR, Webcam).
•OfficeHome (Venkateswara et al., 2017): 12 tasks between 4 domains (Art, Clipart, Product, Real).
For the MNIST→MNISTM task, each training run used a LeNet-like model as the trunk, pretrained on
MNIST. For Office31 and OfficeHome, we used a ResNet50 (He et al., 2016) pretrained (Wightman, 2019) on
ImageNet (Russakovsky et al., 2015), and finetuned this model on every domain. Then for every task, we
started each training run using the model finetuned on the source domain (i.e. the source-only model). We
followed this procedure using 10 UDA algorithms (see Table 2), all implemented in PyTorch (Paszke et al.,
2019).
For each UDA algorithm/task pair, we ran 100 steps of random hyperparameter search using Optuna (Akiba
et al., 2019). This full search was run using two different feature layers: the 2nd-to-last layer (256-dim) and
the penultimate layer (128-dim). Each training run lasted for a fixed number of epochs. Features and logits
for both source and target datasets were saved at regular intervals, 20 times per training run. The final result
was 760,000 datapoints: 10 algorithms * 100 steps of hyperparameter search * 20 checkpoints per training
run * 19 tasks * 2 feature layers.
Table 2: The 10 UDA algorithms used to create the dataset of feature vectors.
Algorithms Category
ATDOC (Liang et al., 2021) Pseudo labeling
BNM (Cui et al., 2020a)
BSP (Chen et al., 2019)SVD loss
CDAN (Long et al., 2017a)
DANN (Ganin et al., 2016)
GVB (Cui et al., 2020b)Adversarial
IM (Shi & Sha, 2012)
MCC (Jin et al., 2020)Info max
MCD (Saito et al., 2018a) Multiple classifier discrepancy
MMD (Long et al., 2015) Feature distance
2.2 Benchmarking the validation methods
We benchmarked the validators described in Sections 1.1 and 1.2, excluding those that are impractical to
apply on a per-checkpoint basis. Computing scores per-checkpoint is preferred because it allows for faster
feedback during training, and a greater likelihood of finding the optimal model. As well, it is how checkpoint
selection is usually done in the supervised setting. The validation methods we excluded are:
•Reverse validation, which is typically applied per training run rather than per checkpoint.
•Proxyrisk, which requires traininga full UDAmodel percheckpoint. Thisincreasestotal training-time
complexity to O(epochs2), and is therefore not practical to use on a large scale.
5Under review as submission to TMLR
•EMS, which requires access to a separate dataset with ground-truth target-labels.
We wanted all validators to give higher scores for better models, so we multiplied the scores of DEV, DEVN,
and Entropy by−1. Each validator can have multiple variants by changing its parameters (see appendix
section E).
The ideal validator ranks model checkpoints in the order of target-domain accuracy. Thus, a suitable
evaluation metric is the Spearman ranking correlation between target-domain accuracy and validation scores.
However, the Spearman correlation treats all samples equally, whereas we are more interested in the samples
with high validation scores.
For example, consider a hypothetical set of validation scores that are perfectly correlated with accuracy, with
the exception of the highest score that breaks the trend and returns a model with 0% accuracy. The set of
scores with perfect correlation is useless, because ultimately, only the model with the highest validation score
is selected. In this example, that model has 0% accuracy.
Thus, to account for this type of scenario, we use the weighted Spearman correlation (Bailey et al., 2018) to
give more weight to the samples with high validation scores (see Figure 1). We set the weight of sample xias:
weight (xi) =/parenleftbiggrank (v(xi))
max
1≤k≤Nrank (v(xk))/parenrightbigg2
(12)
where
•v(xi)is the validation score of sample xi.
•rank (v(xi))is the integer rank obtained by ranking all validation scores in ascending order, such
that the lowest validation score has a rank of 1.
•max
1≤k≤Nrank (v(xk))is the maximum rank of all Nsamples.
See appendix section D for details on how the weighted Spearman correlation is calculated.
2.3 How we define the average weighted Spearman correlation and top 5 training runs
In the next section, some figures and tables make use of the “average weighted Spearman correlation (WSC)
across tasks”, and the “top 5 training runs per algorithm/task pair”.
A validator’s average WSC across tasks is defined as:
Average WSC across tasks =1
TT/summationdisplay
i=1WSC(Ai,Vi) (13)
whereAiis the set of target domain accuracies for task i,Viis the set of validator scores for task i, andTis
the number of tasks.
The top 5 training runs for an algorithm/task pair is defined as:
Ri= max
V∈riV (14)
Top 5 Training Runs =sorted (R)[:5] (15)
whereRiis the maximum validation score obtained in training run i, and sorted (R)isRsorted in descending
order.
6Under review as submission to TMLR
2.4 Advantage of the weighted Spearman correlation
(a) A synthetic example of a poor validator.
Spearman: 74.1. Weighted Spearman: 43.6.
(b) A synthetic example of a better validator.
Spearman: 74.2. Weighted Spearman: 81.1.
(c) ClassSS validator, OfficeHome Art →Real.
Spearman: 60.2. Weighted Spearman: -2.7.
(d) Entropy validator, OfficeHome Real →Art.
Spearman: 87.0. Weighted Spearman: 43.2.
Figure 1: These scatter plots show the advantage of the weighted Spearman correlation over the Spearman
correlation. The Spearman correlation gives roughly the same score for Figures 1a and 1b. In contrast, our
weighted Spearman correlation gives Figure 1a a much lower score, because there are many high validation
scores corresponding with low accuracies. This means that during checkpoint selection, there is a high
chance of selecting a low-accuracy checkpoint. In Figure 1c, the worst accuracies correspond with the highest
validation scores, and in Figure 1d, accuracies ranging from 40% to 70% all have roughly the same validation
score. The Spearman correlation treats all points equally and produces misleading scores for our purposes. In
contrast, our weighted Spearman correlation emphasizes the samples with high validation scores, and heavily
penalizes these two examples.
7Under review as submission to TMLR
3 Results
Here are our main findings:
•Source validation accuracy (the baseline method) outperforms all other validators on Office31 and
OfficeHome when applied to the checkpoints of all UDA algorithms simultaneously (see Figure 2). For
all but one UDA algorithm, source validation accuracy is also the best validator on a per-algorithm
basis (see Table 4).
•Our proposed BNM validator combined with the ATDOC algorithm comprises the best algo-
rithm/validator pair, outperforming all other pairs, including those that use the baseline validation
method (source validation accuracy). See Figure 3 and Table 4.
•Our proposed method DEVN vastly outperforms DEV (see Figure 4). This shows the importance of
weight normalization for making DEV usable in actual applications, rather than in theory.
•Our proposed method ClassAMI significantly outperforms the original ClassSS, when applied to both
source and target features (see Figure 5).
•SND consistently underperforms (see Figure 2 and Figure 6).
•When using an oracle validator (i.e. a validator that can directly compute target domain accuracy),
most UDA algorithms outperform the source-only model (see Table 5a). However, when using
non-oracle validators, UDA algorithms actually degrade accuracy in many cases (see Table 5b).
Table 3: The contributions of our proposed validators.
Existing validator or algorithm Our proposed validator What our proposed validator achieves
BNM (used as an algorithm) BNM (used as a validator) State-of-the-art performance when paired with ATDOC
ClassSS (validator) ClassAMI Significantly better performance than ClassSS
DEV (validator) DEVN Significantly better performance than DEV
4 Conclusion
Our benchmark comparison of validation methods reveals that:
•Our proposed validators significantly outperform the existing methods. However, the baseline (source
validation accuracy) still leads the pack overall.
•Our BNM validator achieves state-of-the-art performance when used with the ATDOC algorithm.
•Even the best validators tend to pick sub-optimal checkpoints, which in many cases causes UDA
algorithms to perform worse than untrained models (see Table 5). Thus, there is much room for
improvement in the effectiveness of existing validation methods.
To unlock the full potential of UDA algorithms and models, more research is needed to improve validator
accuracy and consistency. We hope our large-scale benchmark study, and our three new validators, will serve
as a useful reference for future research in this area.
8Under review as submission to TMLR
Figures and tables
(a) Office31
(b) OfficeHome
Figure 2: The weighted Spearman correlation per validator, averaged across the transfer tasks within Office31
and OfficeHome (see equation 13). The error bars represent the standard deviation across transfer tasks.
9Under review as submission to TMLR
(a) The weighted Spearman correlation for validators
paired with ATDOC, averaged across the Office31
and OfficeHome tasks (see equation 13). The BNM
validator performs the best for this algorithm.
(b) BNM validation scores for the ATDOC algorithm
on the MNIST→MNISTM task.
(c) BNM validation scores for the ATDOC algorithm
on the Office31 DSLR →Webcam task.
(d) BNM validation scores for the ATDOC algorithm
on the OfficeHome Product →Real task.
Figure 3: The BNM validator is effective when paired with the ATDOC algorithm. Figures 3b-3d show the
high correlation this pair achieves across MNIST, Office31, and OfficeHome. The notation X →Y means
that X is the source domain, and Y is the target domain.
10Under review as submission to TMLR
(a) DEV
 (b) DEVN (using standardization)
Figure 4: DEV can produce scores approaching infinity (Figure 4a). Our proposed method, DEVN, fixes this
problem by normalizing the sample weights. (Figure 4b). These plots are for the OfficeHome Clipart →Art
task.
(a) ClassAMI
 (b) ClassSS
Figure 5: We used the Adjusted Mutual Information (ClassAMI) instead of the Silhouette Score (ClassSS)
to achieve a significant improvement for the class clustering validation method. These plots are for the
OfficeHome Real →Clipart task.
11Under review as submission to TMLR
(a) SND applied to the checkpoints of the CDAN
algorithm, on the OfficeHome Clipart →Real task.
The weighted Spearman correlation is -93.1. This is
SND applied to the prediction vectors, with τ= 0.05.
(b) SND applied to the checkpoints of the MMD
algorithm, on the OfficeHome Product →Clipart
task. The weighted Spearman correlation is 4.4. This
is SND applied to the feature vectors, with τ= 0.5.
Figure 6: Examples of the SND validator being a poor predictor of accuracy.
Table 4: The best validator to use for each UDA algorithm. By “best”, we mean that the validator scores the
highest average weighted Spearman correlation (WSC) across Office31 and OfficeHome tasks (equation 13),
for the checkpoints of a particular UDA algorithm.
Algorithm Validator Parameters Average WSC
ATDOC BNM Source Val + Target 92.7±3.0
BNM Accuracy Source Val 89.4±9.0
BSP Accuracy Source Val 83.6±11.2
CDAN Accuracy Source Val 89.0±9.8
DANN Accuracy Source Val 88.4±8.0
GVB Accuracy Source Val 89.1±6.3
IM Accuracy Source Val 89.1±7.2
MCC Accuracy Source Val 89.5±5.4
MCD Accuracy Source Val 90.9±6.5
MMD Accuracy Source Val 88.9±8.1
12Under review as submission to TMLR
Table 5: Even the best validators tend to pick sub-optimal checkpoints, which in many cases causes UDA
algorithms to perform worse than untrained models. These tables show the performance of UDA algorithms
when using an oracle validator (Table 5a) and non-oracle validators (Table 5b). Each value is the average
target-domain accuracy of the top 5 training runs, as determined by the validator (see equation 14). Green
cells have an average accuracy greater than the source-only model. A stronger green color indicates higher
accuracy. The color scheme is shared between the two tables, i.e. the colors in Table 5b are on the same scale
as in Table 5a. Bold indicates the highest value per column, per table. Bolding in Table 5b is independent of
the bolding in Table 5a.
(a) The performance of UDA algorithms when using an oracle validator.
Office31 OfficeHome
MMAD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP
Source only 57.682.780.469.694.371.5 99.041.268.676.760.267.670.560.042.876.268.844.779.1
ATDOC 60.488.884.472.196.672.3 99.647.572.376.863.974.674.065.947.978.473.652.280.9
BNM 63.389.391.373.597.474.8100.0 52.374.279.967.074.276.766.851.980.472.556.881.9
BSP 57.185.378.869.396.469.9 99.843.967.876.260.164.970.060.242.176.069.645.677.5
CDAN 91.688.291.372.796.674.1 99.852.370.977.662.669.072.564.053.279.972.057.181.3
DANN 92.289.691.972.797.174.2 99.853.271.378.063.069.572.664.652.679.773.158.181.7
GVB 78.890.290.971.595.874.6100.0 52.970.478.365.471.274.564.953.481.174.256.982.3
IM 63.289.191.372.796.675.0 99.952.773.480.367.074.076.466.251.180.973.156.581.9
MCC 68.993.292.873.297.675.2100.055.174.781.169.775.977.668.354.582.575.358.083.5
MCD 68.187.883.367.098.766.4100.0 43.367.775.259.868.570.861.844.977.372.049.480.6
MMD 71.687.888.072.197.272.1100.0 50.571.177.464.269.772.164.948.778.872.252.880.5
(b) The performance of UDA algorithms when using the algorithm/validator pairs shown in Table 4.
Office31 OfficeHome
MMAD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP
Source only 57.682.780.469.694.371.5 99.041.268.676.760.267.670.560.042.876.268.844.779.1
ATDOC 58.782.583.568.195.267.9 97.142.569.771.954.768.366.364.338.476.871.148.379.1
BNM 52.283.885.163.293.166.3 96.150.672.078.262.269.673.765.646.379.071.054.080.4
BSP 18.280.474.444.184.043.7 96.841.166.674.956.758.565.254.735.774.867.344.175.8
CDAN 63.982.287.063.890.168.5 95.150.867.976.456.467.968.362.250.078.870.252.779.5
DANN 67.784.188.164.892.168.4 97.650.268.376.256.766.270.460.849.977.969.852.280.2
GVB 46.782.387.055.488.554.9 94.951.367.276.760.464.270.661.950.078.571.353.680.0
IM 47.481.385.565.490.963.9 96.251.571.978.962.771.872.963.849.179.971.855.679.8
MCC 50.285.686.858.094.070.4 98.251.872.879.964.473.373.263.348.980.171.553.781.5
MCD 13.286.779.444.096.645.9100.0 42.365.373.756.666.368.660.641.674.468.847.179.7
MMD 57.979.779.953.388.763.3 96.447.669.076.858.065.469.262.645.876.870.751.478.9
13Under review as submission to TMLR
References
Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. Optuna. Proceedings
of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining , Jul 2019. doi:
10.1145/3292500.3330701. URL http://dx.doi.org/10.1145/3292500.3330701 .
Paul Bailey, Ahmad Emad, Ting Zhang, Qingshu Xie, and Emmanuel Sikali. Weighted and unweighted correlation
methods for large-scale educational assessment: wcorr formulas. air–naep working paper no. 2018-01. nces data r
project series# 02. American Institutes for Research , 2018.
Zhangjie Cao, Lijia Ma, Mingsheng Long, and Jianmin Wang. Partial adversarial domain adaptation. In Proceedings
of the European Conference on Computer Vision (ECCV) , pp. 135–150, 2018.
Woong-Gi Chang, Tackgeun You, Seonguk Seo, Suha Kwak, and Bohyung Han. Domain-specific batch normalization
for unsupervised domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pp. 7354–7362, 2019.
Xinyang Chen, Sinan Wang, Mingsheng Long, and Jianmin Wang. Transferability vs. discriminability: Batch spectral
penalization for adversarial domain adaptation. In International conference on machine learning , pp. 1081–1090.
PMLR, 2019.
Ching-Yao Chuang, Antonio Torralba, and Stefanie Jegelka. Estimating generalization under distribution shifts via
domain-invariant representations. International conference on machine learning , 2020.
Shuhao Cui, Shuhui Wang, Junbao Zhuo, Liang Li, Qingming Huang, and Qi Tian. Towards discriminability and
diversity: Batch nuclear-norm maximization under label insufficient situations. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition , pp. 3941–3950, 2020a.
Shuhao Cui, Shuhui Wang, Junbao Zhuo, Chi Su, Qingming Huang, and Qi Tian. Gradually vanishing bridge for
adversarial domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pp. 12455–12464, 2020b.
Shuhao Cui, Shuhui Wang, Junbao Zhuo, Liang Li, Qingming Huang, and Qi Tian. Fast batch nuclear-norm
maximization and minimization for robust domain adaptation. ArXiv, abs/2107.06154, 2021.
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, Mario
Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. The journal of machine learning
research, 17(1):2096–2030, 2016.
MuhammadGhifary, WBastiaanKleijn, MengjieZhang, DavidBalduzzi, andWenLi. Deepreconstruction-classification
networks for unsupervised domain adaptation. In European conference on computer vision , pp. 597–613. Springer,
2016.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2016.
Ying Jin, Ximei Wang, Mingsheng Long, and Jianmin Wang. Minimum class confusion for versatile domain adaptation.
InEuropean Conference on Computer Vision , pp. 464–480. Springer, 2020.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2014.
Chen-Yu Lee, Tanmay Batra, Mohammad Haris Baig, and Daniel Ulbricht. Sliced wasserstein discrepancy for
unsupervised domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pp. 10285–10295, 2019.
Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for
unsupervised domain adaptation. In International Conference on Machine Learning (ICML) , pp. 6028–6039, July
13–18 2020.
Jian Liang, Dapeng Hu, and Jiashi Feng. Domain adaptation with auxiliary target domain-oriented classifier. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 16632–16642, 2021.
Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with deep adaptation
networks. In International conference on machine learning , pp. 97–105. PMLR, 2015.
14Under review as submission to TMLR
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Unsupervised domain adaptation with residual
transfer networks. arXiv preprint arXiv:1602.04433 , 2016.
Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. Conditional adversarial domain adaptation.
arXiv preprint arXiv:1705.10667 , 2017a.
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Deep transfer learning with joint adaptation
networks. In International conference on machine learning , pp. 2208–2217. PMLR, 2017b.
Zhihe Lu, Yongxin Yang, Xiatian Zhu, Cong Liu, Yi-Zhe Song, and Tao Xiang. Stochastic classifiers for unsupervised
domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp.
9111–9120, 2020.
Poojan Oza, Vishwanath A Sindagi, Vibashan VS, and Vishal M Patel. Unsupervised domain adaption of object
detectors: A survey. arXiv preprint arXiv:2105.13502 , 2021.
Pau Panareda Busto and Juergen Gall. Open set domain adaptation. In Proceedings of the IEEE International
Conference on Computer Vision , pp. 754–763, 2017.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary
DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and
Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library. In H. Wallach,
H. Larochelle, A. Beygelzimer, F. d 'Alché-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Informa-
tion Processing Systems 32 , pp. 8024–8035. Curran Associates, Inc., 2019. URL http://papers.neurips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf .
Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source
domain adaptation. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 1406–1415,
2019.
Viraj Prabhu, Shivam Khare, Deeksha Kartik, and Judy Hoffman. Sentry: Selective entropy optimization via committee
consistency for unsupervised domain adaptation. In Proceedings of the IEEE/CVF International Conference on
Computer Vision , pp. 8558–8567, 2021.
Alan Ramponi and Barbara Plank. Neural unsupervised domain adaptation in NLP—A survey. In Proceedings
of the 28th International Conference on Computational Linguistics , pp. 6838–6855, Barcelona, Spain (Online),
December 2020. International Committee on Computational Linguistics. doi: 10.18653/v1/2020.coling-main.603.
URL https://www.aclweb.org/anthology/2020.coling-main.603 .
Luca Robbiano, Muhammad Rameez Ur Rahman, Fabio Galasso, Barbara Caputo, and Fabio Maria Carlucci.
Adversarial branch architecture search for unsupervised domain adaptation, 2021.
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy,
Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International journal of
computer vision , 115(3):211–252, 2015.
Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. Adapting visual category models to new domains. In
European conference on computer vision , pp. 213–226. Springer, 2010.
Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada. Asymmetric tri-training for unsupervised domain adaptation.
InInternational Conference on Machine Learning , pp. 2988–2997. PMLR, 2017.
Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya Harada. Maximum classifier discrepancy for
unsupervised domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition ,
pp. 3723–3732, 2018a.
Kuniaki Saito, Shohei Yamamoto, Yoshitaka Ushiku, and Tatsuya Harada. Open set domain adaptation by backprop-
agation. In Proceedings of the European Conference on Computer Vision (ECCV) , September 2018b.
Kuniaki Saito, Donghyun Kim, Stan Sclaroff, Trevor Darrell, and Kate Saenko. Semi-supervised domain adaptation
via minimax entropy. ICCV, 2019.
15Under review as submission to TMLR
Kuniaki Saito, Donghyun Kim, Piotr Teterwak, Stan Sclaroff, Trevor Darrell, and Kate Saenko. Tune it the right way:
Unsupervised validation of domain adaptation via soft neighborhood density, 2021.
Swami Sankaranarayanan, Yogesh Balaji, Carlos D Castillo, and Rama Chellappa. Generate to adapt: Aligning
domains using generative adversarial networks. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition , pp. 8503–8512, 2018.
Yuan Shi and Fei Sha. Information-theoretical learning of discriminative clusters for unsupervised domain adaptation.
In John Langford and Joelle Pineau (eds.), Proceedings of the 29th International Conference on Machine Learning
(ICML-12) , ICML ’12, pp. 1079–1086, New York, NY, USA, July 2012. Omnipress. ISBN 978-1-4503-1285-1.
Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon. A dirt-t approach to unsupervised domain adaptation.
arXiv preprint arXiv:1802.08735 , 2018.
Leslie N. Smith and Nicholay Topin. Super-convergence: very fast training of neural networks using large learning
rates.Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications , May 2019. doi:
10.1117/12.2520589. URL http://dx.doi.org/10.1117/12.2520589 .
Baochen Sun, Jiashi Feng, and Kate Saenko. Return of frustratingly easy domain adaptation. In Proceedings of the
AAAI Conference on Artificial Intelligence , volume 30, 2016.
Marco Toldo, Andrea Maracani, Umberto Michieli, and Pietro Zanuttigh. Unsupervised domain adaptation in semantic
segmentation: a review. Technologies , 8(2):35, 2020.
Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across domains and tasks.
InProceedings of the IEEE international conference on computer vision , pp. 4068–4076, 2015.
Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain adaptation. In
Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 7167–7176, 2017.
Matthijs van der Zee. weightedcorr, 2022. URL https://github.com/matthijsz/weightedcorr .
Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for
unsupervised domain adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition ,
pp. 5018–5027, 2017.
Ross Wightman. Pytorch image models. https://github.com/rwightman/pytorch-image-models , 2019.
Yuan Wu, Diana Inkpen, and Ahmed El-Roby. Dual mixup regularized learning for adversarial domain adaptation. In
European Conference on Computer Vision , pp. 540–555. Springer, 2020.
Minghao Xu, Jian Zhang, Bingbing Ni, Teng Li, Chengjie Wang, Qi Tian, and Wenjun Zhang. Adversarial domain
adaptation with domain mixup. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 34, pp.
6502–6509, 2020.
Ruijia Xu, Guanbin Li, Jihan Yang, and Liang Lin. Larger norm more transferable: An adaptive feature norm
approach for unsupervised domain adaptation. In Proceedings of the IEEE/CVF International Conference on
Computer Vision , pp. 1426–1435, 2019.
Kaichao You, Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. Universal domain adaptation. In
Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , pp. 2720–2729, 2019a.
Kaichao You, Ximei Wang, Mingsheng Long, and Michael Jordan. Towards accurate model selection in deep
unsupervised domain adaptation. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the
36th International Conference on Machine Learning , volume 97 of Proceedings of Machine Learning Research , pp.
7124–7133. PMLR, 09–15 Jun 2019b. URL https://proceedings.mlr.press/v97/you19a.html .
Yabin Zhang, Hui Tang, Kui Jia, and Mingkui Tan. Domain-symmetric networks for adversarial domain adaptation.
InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 5031–5040, 2019.
Erheng Zhong, Wei Fan, Qiang Yang, Olivier Verscheure, and Jiangtao Ren. Cross validation framework to choose
amongst models and datasets for transfer learning. In José Luis Balcázar, Francesco Bonchi, Aristides Gionis, and
Michèle Sebag (eds.), Machine Learning and Knowledge Discovery in Databases , pp. 547–562, Berlin, Heidelberg,
2010. Springer Berlin Heidelberg.
16Under review as submission to TMLR
A Glossary
•Model: a function that receives some input (e.g. photographic images), and returns a label for each item in
that input.
•Domain adaptation : a type of machine-learning algorithm that repurposes existing models to work in
new domains (a.k.a. target domains). For example, the existing model might work on photographs of food,
whereas the target domain contains drawings of food.
•Unsupervised domain adaptation (UDA) : a type of domain adaptation where the target-domain does
not have any existing class labels.
•Validation method (validator) : a function that evaluates how closely a model’s output reflects certain
attributes of the dataset, such as labels. The validator will return a quality score. Ideally, the quality score
will indicate how similar the model’s output is to the dataset attributes.
•UDA validation method : a validation method that estimates target domain accuracy, without having
access to target labels. An effective UDA validation method is one that reliably estimates target-domain
accuracy. For example, a higher score returned by an effective UDA validation method will reliably indicate
that the target-domain accuracy is high.
•Target-domain accuracy : a model’s accuracy in the target domain.
•Oracle validation method : a validation method that has access to existing target labels and is therefore
able to directly compute target-domain accuracy. This contrasts with UDA, in which no target labels are
available, and consequently, accuracy can only be estimated. When target labels are available, they should
be used during training, as this will improve the model’s target-domain accuracy. This type of training is
known as semi-supervised or supervised domain adaptation. On the other hand, when target labels are not
available, UDA is the only training method possible.
B What are validation methods, and why are they important?
In this paper, we compare the accuracy of various validation methods. Validation methods are functions that are used
to evaluate the accuracy of machine-learning models, or in the case of this paper, unsupervised domain-adaptation
models. This kind of research is essential, for the following reasons.
To date, most UDA papers have focused on improvements to the training procedure (algorithm), with the goal of
maximizing target-domain accuracy. These papers tend to use the oracle validation method to evaluate their models,
which is useful only when target labels are available. In contrast, when target labels are not available, the oracle
validation method cannot be used. In that case, UDA validation methods are the only viable choice.
Unfortunately, without access to target labels, UDA validation methods tend to produce scores that are not 100%
correlated with target-domain accuracy. For example, in an extreme case, the UDA validation method could return a
high score for a low-accuracy model, and a low score for a high-accuracy model. Even in less extreme scenarios, the
score might mislead the user into selecting a model that is not the most accurate one available. Yet achieving the
highest possible accuracy is crucial in most application scenarios.
B.1 How validation methods are used
Here is what a typical model-selection workflow looks like:
1. Select a UDA algorithm that you think will train your model effectively.
2.Set the hyperparameters either arbitrarily, or by using a hyperparameter optimizer. The UDA algorithm and
hyperparameters will determine how your model is trained.
3.Use the UDA algorithm to train your model for an arbitrary amount of time, and save a version (checkpoint)
of the model at arbitrary regular intervals.
4.To evaluate each checkpoint, employ whatever UDA validation method you think will correlate well with
target-domain accuracy. The goal is to obtain validation scores that are as accurate as possible.
5. Keep the checkpoint with the highest validation score. Discard all other checkpoints.
6. Repeat steps 2-5 an arbitrary number of times, or until the best validation scores start to plateau.
At the end of this procedure, the model with the highest validation score will typically be deployed in some application.
(For example, the model might be used on a smartphone to classify images of food.)
17Under review as submission to TMLR
B.2 Why validation methods are an important area of research
The above model-selection workflow optimizes for a high validation score, but the goal is to have a model with high
target-domain accuracy. UDA validation scores are not perfectly correlated with target-domain accuracy. Thus, the
model with the highest validation score might have sub-optimal target-domain accuracy. The lower the correlation,
the more likely that a sub-optimal model will be selected inadvertently.
Our research shows that existing UDA validation methods have considerable room for improvement. For example,
the model with the best validation score often has low target-domain accuracy. In other words, the model that gets
chosen for deployment actually performs poorly, even though the validation method indicates that it performs well.
Until UDA validation methods are able to produce more reliable results, it will be difficult to determine which models
have the highest target-domain accuracy. As long as this is the case, the full potential of UDA algorithms will be
unrealized.
Despite this fact, there are far more papers on UDA algorithms than on UDA validation methods. Yet validation
methods have much more room for improvement. A UDA algorithm paper might improve target domain accuracy (as
computed by an oracle) by a single percentage point, from 89% to 90% for example. But the checkpoint with the
highest validation score might have only 70% target-domain accuracy. Thus, the validation method has a much larger
effect on accuracy than the choice of UDA algorithm. Hence, research into UDA validation methods is crucial.
C Methodology summary
Our benchmarking process consisted of the following steps:
1. Create a dataset of model outputs:
•Select ten UDA algorithms that represent a variety of algorithm types.
•For each UDA algorithm, randomly create 100 hyperparameter settings.
•For each hyperparameter setting, train a model on a UDA task for a fixed number of iterations, and
save a model checkpoint at regular intervals. Each checkpoint consists of only the outputs of the model.
2. Calculate how accurate various validation methods are at ranking model checkpoints:
•Select eight UDA validation methods.
•Using each validation method in turn, compute a validation score for every checkpoint. (Remember that
validation scores are computed using a UDA validation method. In contrast, target-domain accuracies
are computed using the oracle validation method.)
•For the results of each validation method, compute the weighted Spearman correlation.
D Calculating the weighted Spearman correlation
Our evaluation of validation methods is based on the weighted Spearman correlation described in Bailey et al. (2018)
and implemented by van der Zee (2022). Here we show a summary of the calculations described in Bailey et al. (2018),
with a few changes in notation.
The Pearson correlation is:
rPearson =/summationtextN
i=1(xi−x)(yi−y)/radicalig/summationtextN
i=1(xi−x)2/summationtextN
i=1(yi−y)2(16)
The weighted Pearson correlation scales the terms by a weight for each (x,y)pair:
18Under review as submission to TMLR
rWeighted Pearson =/summationtextN
i=1wi(xi−/hatwidex)(yi−/hatwidey)/radicalig/summationtextN
i=1wi(xi−/hatwidex)2/summationtextN
i=1wi(yi−/hatwidey)2(17)
/hatwidex=/summationtextN
i=1wixi/summationtextN
i=1wi(18)
/hatwidey=/summationtextN
i=1wiyi/summationtextN
i=1wi(19)
wherewiis the weight of each pair, and Nis the number of pairs.
The Spearman correlation is the Pearson correlation between rankings, i.e. xiandyirepresent the rank of sample iin
thexandyvariables. To compute the weighted Spearman correlation, let γjbe the weighted rank of the jth sample:
γj=aj+bj (20)
aj=N/summationdisplay
i=1wi 1(rank i<rank j) (21)
bj=t+ 1
2wj (22)
wj=1
tN/summationdisplay
i=1wi 1(rank i=rank j) (23)
1is a function that equals 1 if the expression inside is true, and 0 otherwise, and tis the number of samples that have
the same rank as sample j.
Theγjis computed for all xandysamples to obtain γxandγy. Thenγxandγyare plugged into equations 17-19,
taking the place of the xandyvariables.
19Under review as submission to TMLR
E Validator parameters explained
Table 6: Each validator has its own settings. In the other tables and figures in this paper, we use short
descriptions to indicate what settings are used. This table explains what those short descriptions mean. Note
that we L2-normalized the inputs to ClassSS because it performed worse with un-normalized inputs.
Validator Parameters Explanation
AccuracySource Train Accuracy(Source train predictions)
Source Val Accuracy(Source validation predictions)
BNMSource Train BNM(Source train predictions)
Source Train + Target BNM(Source train predictions) +BNM(Target predictions)
Source Val BNM(Source validation predictions)
Source Val + Target BNM(Source validation predictions) +BNM(Target predictions)
Target BNM(Target predictions)
ClassAMISource + Target Features ClassAMI(concat(Source train features, Target features))
Source + Target Logits ClassAMI(concat(Source train logits, Target logits))
Target Features ClassAMI(Target features)
Target Logits ClassAMI(Target logits)
ClassSSSource + Target Features ClassSS(concat(Source train normalized features, Target normalized features))
Source + Target Logits ClassSS(concat(Source train normalized logits, Target normalized logits))
Target Features ClassSS(Target normalized features)
Target Logits ClassSS(Target normalized logits)
DEVFeatures The discriminator is trained on feature vectors.
Logits The discriminator is trained on logits.
Preds The discriminator is trained on prediction vectors.
DEVNFeatures, max normalization The discriminator is trained on feature vectors. The sample weights are max-normalized.
Features, standardization The discriminator is trained on feature vectors. The sample weights are standardized.
Logits, max normalization The discriminator is trained on logits. The sample weights are max-normalized.
Logits, standardization The discriminator is trained on logits. The sample weights are standardized.
Preds, max normalization The discriminator is trained on prediction vectors. The sample weights are max-normalized.
Preds, standardization The discriminator is trained on prediction vectors. The sample weights are standardized.
EntropySource Train Entropy(Source train predictions)
Source Train + Target Entropy(Source train predictions) +Entropy(Target predictions)
Source Val Entropy(Source validation predictions)
Source Val + Target Entropy(Source validation predictions) +Entropy(Target predictions)
Target Entropy(Target predictions)
SNDFeatures,τ= 0.05 The similarity matrix is derived from target features. Softmax temperature is 0.05.
Features,τ= 0.1 The similarity matrix is derived from target features. Softmax temperature is 0.1.
Features,τ= 0.5 The similarity matrix is derived from target features. Softmax temperature is 0.5.
Logits,τ= 0.05 The similarity matrix is derived from target logits. Softmax temperature is 0.05.
Logits,τ= 0.1 The similarity matrix is derived from target logits. Softmax temperature is 0.1
Logits,τ= 0.5 The similarity matrix is derived from target logits. Softmax temperature is 0.5
Preds,τ= 0.05 The similarity matrix is derived from target predictions. Softmax temperature is 0.05
Preds,τ= 0.1 The similarity matrix is derived from target predictions. Softmax temperature is 0.1
Preds,τ= 0.5 The similarity matrix is derived from target predictions. Softmax temperature is 0.5
Table 7: The validator parameters categorized by function.
Validators Parameters
Accuracy, BNM, Entropy Dataset splits
ClassAMI, ClassSS Dataset splits, Choice of feature vector
DEVChoice of feature vector
DEVN Choice of feature vector, type of normalization
SNDChoice of feature vector, softmax temperature
20Under review as submission to TMLR
F Training methodology details
Table 8: A list of the models used in our experiments. We created the dataset of model outputs using two
feature layers: FL3 and FL6. Every checkpoint contains the feature layer (FL3 or FL6) and the logits. The
discriminator is used only for adversarial methods. It receives the feature layer as input, but keeps the same
depth regardless of feature layer.
Layers Feature name
Trunk LeNetorResNet50
ClassifierLinear(256)
ReLU()
Dropout(0.5)
Linear(128)
ReLU()
Dropout(0.5)
Linear(num_cls)
Softmax()FL3
FL6
Logits
Preds
DiscriminatorLinear(2048)
ReLU()
Linear(2048)
ReLU()
Linear(1)
Table 9: A list of various experiment settings. The learning rate (lr) is one of the hyperparameters. The
same lr is used by trunk, classifier, and discriminator.
Category Settings
OptimizerAdam (Kingma & Ba, 2014)
Weight decay of 1e-4
lr∈log([1e-5,0.1])
LR schedulerOne Cycle (Smith & Topin, 2019)
5% warmup period
lrinit=lrmax/100
lrfinal = 0
Cosine annealing
Batch size 64 source + 64 target
Epochs / checkpoint intervalDigits: 100 / 5
Office31 (W and D as target): 2000 / 100
Office31 (A as target): 200 / 10
OfficeHome: 200 / 10
Training image transformsResize(256)
RandomCrop(224)
RandomHorizontalFlip()
Normalize()
Validation image transformsResize(256)
CenterCrop(224)
Normalize()
MNIST image transformsResize(32)
GrayscaleToRGB()
Normalize()
21Under review as submission to TMLR
Table 10: A list of the hyperparameter search settings used in the experiment.
Algorithm Hyperparameter Search space
ATDOCλatdoc
katdoc
λL[0,1]
int([5, 25], step=5)
[0,1]
BNMλbnm
λL[0,1]
[0,1]
BSPλbsp
λLlog([1e-6,1])
[0,1]
CDANλD
λG
λL[0,1]
[0,1]
[0,1]
DANNλD
λgrl
λL[0,1]
log([0.1,10])
[0,1]
GVBλD
λBG
λBD
λgrl[0,1]
[0,1]
[0,1]
log([0.1,10])
IMλimax
λL[0,1]
[0,1]
MMDλF
λL
γexp[0,1]
[0,1]
int([1,8])
MCCλmcc
Tmcc
λL[0,1]
[0.2,5]
[0,1]
MCDNmcd
λL
λdiscint([1,10])
[0,1]
[0,1]
22Under review as submission to TMLR
Table 11: Description of every hyperparameter that is mentioned in Table 10.
Hyperparameter Description
λatdoc ATDOC loss weight
λbnm BNM loss weight
λbsp BSP loss weight
λdisc Classifier discrepancy loss weight for MCD
λgrl Gradient reversal weight, i.e. gradients are multiplied by −λgrl
λimax Information maximization loss weight
λmcc MCC loss weight
λBG Generator bridge loss weight for GVB
λBD Discriminator bridge loss weight for GVB
λD Discriminator loss weight
λF Feature distance loss weight
λG Generator loss weight
λL Source classification loss weight
γexp Exponent of the bandwidth multiplier for MMD. For example, if
γexp= 2, then the bandwidths used will be {2−2x,2−1x,20x,21x,22x},
wherexis the base bandwidth.
katdoc Number of nearest neighbors to retrieve for computing pseudolabels in
ATDOC
Nmcd Number of times the MCD generator is updated per batch
Tmcc Softmax temperature used by MCC
23Under review as submission to TMLR
G Correlation tables
Table 12: Summary of tables that show the weighted Spearman correlation of the benchmarked validators.
Algorithm Office31 & OfficeHome MNIST →MNISTM (MM)
All combined Table 13 Table 24
ATDOC Table 14 Table 25
BNM Table 15 Table 25
BSP Table 16 Table 25
CDAN Table 17 Table 25
DANN Table 18 Table 25
GVB Table 19 Table 25
IM Table 20 Table 25
MCC Table 21 Table 25
MCD Table 22 Table 25
MMD Table 23 Table 25
What the green coloring means
For all tables, the green coloring indicates better performance. The greener the cell color, the better the performance,
compared to the Source Val Accuracy validator. The best value per column is bolded. The Mean and Std columns are
the mean and standard deviation of all task or algorithm columns. A high mean and low standard deviation reflect
good performance.
G.1 Weighted Spearman Correlation for Office31 and OfficeHome
Table 13: The weighted Spearman correlation of each validator/task pair, using the checkpoints of all
algorithms simultaneously.
AD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP Mean Std
AccuracySource Train 74.475.585.272.780.163.761.365.363.459.363.764.577.472.679.263.973.773.970.57.3
Source Val 81.684.277.077.281.772.495.995.596.984.288.989.092.990.995.194.192.694.388.07.4
BNMSource Train 74.476.880.159.476.146.460.565.853.751.455.453.971.368.372.148.367.060.663.410.2
Source Train + Target 74.183.486.270.485.828.976.879.272.766.174.671.472.278.077.256.579.969.572.412.6
Source Val 75.777.679.373.381.255.683.284.076.553.260.156.379.979.078.669.183.476.973.59.9
Source Val + Target 76.883.085.677.487.147.381.483.175.963.670.566.774.379.378.361.582.474.474.99.7
Target 73.181.684.871.285.429.475.578.472.766.875.672.871.677.176.956.779.369.172.112.2
ClassAMISource + Target Features 75.983.885.360.786.253.484.583.681.180.083.785.783.486.885.569.889.179.779.99.2
Source + Target Logits 74.984.185.159.486.252.583.982.779.977.482.183.581.486.784.268.289.078.478.99.4
Target Features -14.9-35.4-14.2 -9.1-16.4 -7.5-45.5-40.9-41.6-42.2-43.7-42.1-34.1-30.8-34.6-40.2-35.7-42.2-31.712.7
Target Logits -18.5-35.6-17.1-14.9-21.2-10.7-55.0-43.9-42.7-45.6-46.9-44.0-39.0-40.8-39.1-44.1-44.0-44.1-36.012.8
ClassSSSource + Target Features 34.448.543.041.944.622.4-7.70.28.8-14.3 6.21.10.917.015.1 2.812.415.216.318.5
Source + Target Logits 39.241.639.436.443.221.2 1.910.814.0-4.917.111.8 5.521.119.810.212.822.020.214.0
Target Features 44.458.639.647.636.130.9-30.4-10.3 -2.7-28.7 -0.3-5.7-23.8 -9.50.9-9.2-10.010.9 7.727.2
Target Logits 45.560.334.149.834.229.7-12.1 -0.63.3-20.0 9.93.7-17.8 6.45.5-2.72.515.813.722.8
DEVFeatures -52.0-59.119.833.343.8 0.826.330.6 7.9-22.4-15.0 -6.3-11.2 -0.0-5.5-27.5 -0.4-8.9-2.626.8
Logits -19.3-22.343.945.960.511.148.248.337.127.130.041.524.939.540.8 9.647.236.230.622.0
Preds -36.4-45.5-35.9-40.2-40.1-54.7-17.0-12.6-19.4-33.048.155.3-41.941.947.6-49.749.540.2 -8.040.4
DEVNFeatures, max normalization 77.477.674.762.775.761.294.594.795.681.984.985.591.887.992.690.490.491.183.910.2
Features, standardization 61.953.882.856.180.459.389.791.689.583.682.581.490.081.687.085.186.485.079.312.0
Logits, max normalization 77.280.770.662.374.959.994.594.595.481.084.585.090.986.691.689.789.891.283.410.4
Logits, standardization 68.373.176.258.680.953.590.791.190.280.379.978.287.878.086.181.984.885.679.210.1
Preds, max normalization 77.581.164.960.769.059.894.794.295.376.882.581.090.189.792.289.192.292.482.411.6
Preds, standardization 70.475.463.349.465.651.289.990.290.363.977.674.483.985.086.482.288.087.476.412.8
EntropySource Train 69.269.171.855.668.044.457.762.348.446.350.649.963.665.067.743.263.653.658.39.2
Source Train + Target 71.371.358.564.061.058.666.772.868.458.966.863.763.267.771.155.370.563.465.25.1
Source Val 41.445.159.158.761.749.561.665.067.943.851.849.267.670.171.163.070.665.359.09.5
Source Val + Target 63.958.256.464.559.955.262.969.169.055.362.860.063.367.070.658.568.863.862.74.8
Target 65.962.746.263.654.162.263.269.967.358.666.764.159.864.067.954.466.261.062.15.7
SNDFeatures,τ= 0.05 -82.4-82.1-77.9-91.6-78.8-89.1-80.4-82.9-90.3-77.7-85.5-85.3-77.9-83.3-86.1-85.6-81.7-85.9-83.6 4.1
Features,τ= 0.1 -81.2-80.6-74.8-87.5-75.0-87.6-79.1-80.3-86.2-75.9-82.1-82.7-75.7-80.1-82.8-80.7-78.5-82.8-80.7 3.8
Features,τ= 0.5 -83.3-84.7-80.7-77.9-81.0-78.6-82.6-82.9-79.9-81.6-83.8-84.5-82.2-80.1-82.2-75.6-79.3-81.1-81.22.3
Logits,τ= 0.05 -83.7-82.1-78.1-90.8-81.6-89.6-81.9-85.8-92.0-80.1-87.6-87.9-80.2-83.9-87.8-87.3-82.9-87.0-85.0 3.9
Logits,τ= 0.1 -82.7-80.2-75.1-87.4-78.7-88.6-80.3-83.6-89.6-78.4-85.2-85.7-77.3-79.6-85.3-83.9-79.4-83.9-82.5 4.0
Logits,τ= 0.5 -79.2-78.7-73.3-75.9-74.2-77.3-82.7-82.7-86.2-79.8-84.2-84.6-82.8-82.8-84.6-82.0-83.3-82.8-80.9 3.6
Preds,τ= 0.05 -80.4-79.1-68.4-88.8-71.8-86.5-79.7-84.8-90.8-78.4-87.0-86.2-76.4-81.3-86.0-85.7-81.7-86.1-82.2 5.7
Preds,τ= 0.1 -78.7-76.7-64.9-87.1-68.7-87.2-78.6-83.0-89.9-77.4-85.7-84.9-74.1-78.5-84.4-84.8-79.7-84.9-80.5 6.4
Preds,τ= 0.5 -79.2-78.8-71.2-85.4-72.6-83.9-82.1-84.1-86.9-80.7-85.5-85.5-78.8-81.0-84.4-83.4-82.4-84.0-81.6 4.2
24Under review as submission to TMLR
Table 14: The weighted Spearman correlation of each validator/task pair for ATDOC .
AD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP Mean Std
AccuracySource Train 79.784.481.482.572.088.749.154.646.772.042.756.486.856.680.049.958.468.567.215.0
Source Val 82.388.385.389.574.190.590.592.091.486.879.780.190.772.389.193.487.193.886.56.2
BNMSource Train 86.090.089.590.981.788.674.681.366.885.163.979.993.076.891.451.775.981.880.510.7
Source Train + Target 92.593.994.695.385.294.686.692.789.794.694.094.095.890.897.791.687.495.392.63.3
Source Val 87.391.090.892.782.489.390.393.691.089.283.788.995.087.295.689.985.892.089.83.5
Source Val + Target 91.993.593.694.684.294.189.893.892.493.792.693.495.891.297.594.087.294.992.73.0
Target 91.592.793.294.583.494.486.892.591.795.196.394.494.491.297.992.687.896.2 92.63.5
ClassAMISource + Target Features 81.588.688.286.886.586.279.787.970.287.982.485.691.276.391.055.466.278.781.79.2
Source + Target Logits 81.689.087.287.082.987.675.286.970.685.480.678.790.569.490.358.362.080.180.29.3
Target Features -27.2-42.5-16.0 4.5-19.1 7.7-54.1-46.9-49.6-47.7-31.2-49.0-23.6-23.2-24.8-36.7-65.6-38.1-32.418.8
Target Logits -26.7-43.8 -5.94.6-16.514.5-58.3-39.0-46.4-45.9-25.0-44.0-21.6-28.6-22.2-24.8-68.1-27.5-29.220.2
ClassSSSource + Target Features 61.263.438.665.126.777.5-27.5 -2.3-1.4-24.7 -4.8-25.516.9-9.229.916.3-36.521.915.934.2
Source + Target Logits 59.631.725.963.025.464.9-29.8 -7.55.2-14.415.8-9.717.2-3.936.3 5.2-40.620.014.729.3
Target Features 25.037.242.761.026.069.1-43.9 -8.7-17.4-39.133.9-21.2-13.6-18.6 -1.1-3.0-44.110.3 5.233.8
Target Logits 33.851.627.365.924.658.8-27.6-11.1 -8.4-33.627.3-16.3-10.0 -6.59.7-9.2-30.6 7.28.529.9
DEVFeatures -16.2 -7.136.970.1 8.934.530.942.122.5-0.72.415.525.332.235.9-27.4 -8.9-2.316.423.9
Logits -11.9 -2.248.876.235.5-0.848.660.332.868.850.783.178.768.984.5 2.869.950.346.930.5
Preds -25.6-33.8-25.2-24.7-26.5-60.0-26.4-15.5-19.5-27.456.575.7-26.061.164.0-56.466.532.4 -0.644.4
DEVNFeatures, max normalization 83.289.086.791.074.990.491.091.790.189.583.883.693.275.291.893.488.694.287.85.5
Features, standardization 75.681.387.392.167.989.692.493.178.792.287.487.394.978.994.289.691.694.687.17.4
Logits, max normalization 83.889.887.391.775.990.291.692.290.689.284.484.593.075.391.792.588.394.088.15.3
Logits, standardization 78.587.790.193.075.688.993.993.584.492.289.992.794.580.294.984.591.492.288.85.7
Preds, max normalization 84.589.785.989.675.390.093.593.292.588.088.386.892.677.192.893.288.894.588.75.2
Preds, standardization 81.688.885.288.974.188.187.787.488.783.192.294.391.384.896.088.089.792.487.94.9
EntropySource Train 76.983.290.490.881.487.577.883.168.283.567.582.587.879.790.753.474.882.880.19.3
Source Train + Target 81.679.983.189.980.789.678.786.676.886.185.686.583.577.585.060.258.376.280.38.5
Source Val 64.677.789.190.480.986.778.883.980.385.384.187.587.786.692.186.865.482.882.87.3
Source Val + Target 81.377.683.589.280.388.775.082.076.585.185.684.983.076.883.667.356.175.379.57.8
Target 78.974.376.787.076.788.072.080.272.581.181.879.878.170.276.255.352.967.875.09.0
SNDFeatures,τ= 0.05 -76.5-69.7-69.5-83.0-71.3-84.1-70.1-75.2-81.9-64.3-83.7-76.5-61.6-73.9-75.6-80.1-73.7-80.9-75.1 6.4
Features,τ= 0.1 -76.8-70.5-70.1-82.8-71.5-83.8-72.1-75.3-80.9-65.6-83.8-77.6-62.3-74.8-76.0-75.3-74.4-80.6-75.2 5.8
Features,τ= 0.5 -79.2-75.0-77.5-85.0-77.3-87.3-80.3-82.3-86.2-73.5-88.1-84.5-72.8-82.5-83.1-82.7-79.4-85.8-81.3 4.5
Logits,τ= 0.05 -78.1-68.2-67.8-84.4-72.8-87.0-66.4-76.8-87.7-64.6-87.7-78.0-60.7-76.6-76.0-87.3-74.0-83.6-76.5 8.3
Logits,τ= 0.1 -78.6-68.7-67.3-83.5-72.0-86.2-66.9-75.8-85.9-64.6-86.9-77.7-61.1-75.9-75.9-84.6-74.3-82.1-76.0 7.7
Logits,τ= 0.5 -79.7-71.2-72.9-85.5-76.7-87.6-75.5-79.1-86.2-69.7-89.0-82.8-70.1-82.6-80.5-84.0-78.4-84.9-79.8 5.9
Preds,τ= 0.05 -78.2-67.4-69.7-84.8-72.7-88.4-63.3-78.8-89.4-65.7-88.1-80.3-62.3-76.6-76.5-89.4-74.1-86.4-77.3 8.9
Preds,τ= 0.1 -78.1-67.7-69.0-84.4-71.8-87.8-63.5-78.1-89.1-65.8-87.1-80.3-62.2-75.8-76.3-90.3-73.6-85.9-77.0 8.8
Preds,τ= 0.5 -79.4-69.4-72.7-85.1-74.4-87.9-70.4-79.8-88.1-67.9-88.0-83.2-64.6-80.9-79.5-85.8-75.8-86.1-78.8 7.3
Table 15: The weighted Spearman correlation of each validator/task pair for BNM.
AD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP Mean Std
AccuracySource Train 75.578.390.272.480.651.165.071.664.854.257.960.873.270.170.657.971.162.468.29.6
Source Val 82.289.884.378.285.661.397.497.697.885.487.690.693.693.094.796.197.296.289.49.0
BNMSource Train 65.672.468.634.073.3-5.453.156.436.830.820.741.761.759.255.227.853.044.847.219.9
Source Train + Target 65.680.380.142.085.5-34.268.076.268.650.252.867.563.473.074.045.474.367.961.126.0
Source Val 65.873.272.154.980.010.779.380.475.230.829.948.674.775.673.363.481.275.063.620.0
Source Val + Target 65.978.279.655.686.5-10.875.379.673.845.944.361.466.574.674.752.078.172.964.121.7
Target 65.779.879.542.084.8-34.366.576.068.851.854.569.963.073.174.645.974.568.261.325.9
ClassAMISource + Target Features 68.385.590.958.889.818.584.987.287.566.573.985.081.289.990.173.392.385.578.317.3
Source + Target Logits 67.684.788.958.289.419.481.885.386.064.272.482.778.789.489.272.991.584.577.016.8
Target Features -16.4-32.8 5.2-14.3 -9.7-12.7-43.5-54.3-39.7-35.3-41.3-42.4-25.8-32.4-41.6-20.6-41.2-52.3-30.615.7
Target Logits -12.4-35.211.5-16.4 -8.0-6.5-48.5-48.4-35.1-33.4-42.4-42.2-29.6-36.6-34.9-19.9-43.4-50.3-29.516.8
ClassSSSource + Target Features 26.842.861.239.559.8-8.0-19.4 7.716.4-10.9 1.28.3-6.717.219.4 4.25.416.615.622.4
Source + Target Logits 7.843.449.035.755.8-10.1-12.0 5.412.7-5.78.419.2-3.75.19.94.1-0.410.513.119.5
Target Features 43.461.859.846.655.7 3.0-49.6 -3.110.4-17.2 -0.14.3-24.6-17.9 5.6-10.1-23.614.3 8.831.5
Target Logits 21.568.047.152.251.4 0.4-41.6 -4.38.5-20.2 6.513.0-21.6-10.3 -0.5-6.8-15.910.7 8.828.6
DEVFeatures -33.0-33.315.432.451.325.629.440.224.7-16.6 -8.33.3-4.97.9-14.2 -5.9-0.9-8.3 5.823.6
Logits 20.325.963.347.072.834.751.764.478.423.122.544.119.335.738.423.051.463.743.318.8
Preds -24.1-38.6-42.7-36.7-47.4-45.8-29.0-10.0-25.5-30.465.378.9-35.366.075.1-53.572.379.1 1.051.7
DEVNFeatures, max normalization 77.585.577.354.079.338.196.697.196.180.776.989.192.790.993.994.596.095.184.015.4
Features, standardization 79.058.178.446.677.432.391.193.789.783.879.985.689.782.886.489.090.287.979.016.2
Logits, max normalization 74.286.972.954.378.838.596.897.195.978.975.488.591.989.893.594.495.794.783.215.5
Logits, standardization 64.773.773.448.081.733.092.893.691.479.774.581.487.780.886.787.590.286.278.215.5
Preds, max normalization 72.787.470.854.175.838.296.597.096.076.273.587.691.090.092.893.696.294.482.415.8
Preds, standardization 65.978.163.641.165.330.090.192.290.562.071.184.883.279.689.286.287.990.575.117.3
EntropySource Train 62.471.762.327.369.9-9.149.558.233.124.119.339.452.359.153.123.551.040.743.820.3
Source Train + Target 69.080.774.758.680.616.358.473.870.443.850.164.551.564.673.754.669.466.662.315.1
Source Val 42.164.567.647.575.8 7.155.662.872.116.626.243.156.465.469.059.071.064.053.719.2
Source Val + Target 61.575.675.155.481.410.755.968.771.537.944.359.951.664.873.156.269.365.259.916.2
Target 68.479.368.558.978.117.755.971.070.645.352.266.949.164.473.255.968.166.361.714.1
SNDFeatures,τ= 0.05 -77.9-85.6-83.9-88.3-86.5-66.3-82.0-82.6-92.5-80.7-89.7-84.5-80.5-82.8-87.6-90.4-81.7-84.2-83.8 5.6
Features,τ= 0.1 -78.0-84.7-80.5-87.7-82.8-81.6-79.5-81.0-87.2-76.4-85.4-82.2-78.2-78.0-85.1-83.7-77.8-82.7-81.83.3
Features,τ= 0.5 -80.4-86.0-81.3-73.7-82.9-58.8-83.4-85.3-83.1-85.4-86.2-85.7-86.2-81.5-86.3-77.8-81.5-83.3-81.6 6.4
Logits,τ= 0.05 -78.8-87.3-86.7-86.3-89.4-75.0-82.9-85.2-96.2-86.4-94.5-87.7-85.9-86.8-90.2-92.2-84.0-85.1-86.7 4.9
Logits,τ= 0.1 -80.1-88.2-83.4-90.0-87.3-89.3-82.2-84.4-94.3-85.0-93.5-86.8-84.0-82.7-88.9-89.9-82.1-84.9-86.5 3.9
Logits,τ= 0.5 -78.9-85.3-77.9-68.0-78.5-50.7-83.3-82.5-87.0-84.9-87.5-83.8-85.9-84.5-85.6-84.4-82.1-83.6-80.8 8.5
Preds,τ= 0.05 -79.7-89.1-87.8-83.6-89.6-63.1-82.4-84.3-91.4-85.6-90.6-87.0-86.9-86.6-88.2-88.2-83.6-83.5-85.1 6.1
Preds,τ= 0.1 -80.2-89.6-89.5-96.1-90.4-91.0-82.9-84.5-96.2-86.1-94.5-87.6-87.3-88.2-91.5-92.3-84.3-85.3-88.8 4.4
Preds,τ= 0.5 -80.5-86.8-68.8-84.7-66.7-86.5-79.2-83.8-92.1-84.3-88.7-83.9-77.8-68.3-84.0-89.7-78.8-84.6-81.6 7.1
25Under review as submission to TMLR
Table 16: The weighted Spearman correlation of each validator/task pair for BSP.
AD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP Mean Std
AccuracySource Train 71.361.575.780.066.181.933.534.646.534.537.945.870.146.164.256.255.858.556.715.5
Source Val 83.384.063.281.965.085.195.396.195.759.476.676.887.286.491.995.987.793.883.611.2
BNMSource Train 33.011.122.427.9 1.723.329.234.736.351.254.353.152.536.650.958.448.050.037.515.7
Source Train + Target 16.8-1.88.221.9-4.822.624.733.441.153.256.654.747.225.149.257.139.346.732.819.2
Source Val 24.7 0.720.123.9-0.319.927.233.143.050.553.550.052.236.850.762.242.849.935.617.6
Source Val + Target 16.9-2.713.422.2-3.720.823.631.441.551.954.551.948.528.549.258.337.846.732.818.6
Target 9.7-3.6-20.017.0-13.921.514.226.538.651.852.351.439.616.846.153.227.241.026.122.2
ClassAMISource + Target Features 68.836.6 6.044.910.467.627.436.753.060.843.863.879.3 5.676.077.826.062.247.023.9
Source + Target Logits 71.931.715.850.314.171.025.340.256.159.949.367.682.8 5.277.778.329.261.649.323.7
Target Features -69.5-65.5-65.5-47.5-57.3-40.4-67.4-51.9-34.6-61.9-70.0-61.7-54.5-64.3-29.1-54.7-45.7-49.2-55.011.7
Target Logits -65.4-64.6-65.9-51.2-59.1-40.1-81.7-58.7-39.8-68.8-70.9-64.6-61.5-76.0-40.1-57.7-67.0-60.7-60.811.4
ClassSSSource + Target Features -64.9-27.2-46.3 1.2-56.4-15.2-79.2-80.8-76.0-72.6-74.3-75.8-66.8-78.2-73.1-70.9-70.7-73.4-61.223.2
Source + Target Logits -44.3-25.0-40.8-10.4-43.5 7.0-76.9-74.7-57.5-67.5-68.7-64.8-63.3-76.1-67.7-59.2-67.5-62.5-53.522.8
Target Features -48.5-20.1-47.3 -4.8-56.9 -3.7-80.3-80.0-73.5-78.7-69.6-74.1-75.0-83.0-70.1-69.4-78.6-71.9-60.324.9
Target Logits -51.2-14.0-45.4 1.5-50.611.0-82.4-76.5-62.3-79.7-65.3-69.1-76.3-82.5-67.2-64.6-78.9-59.6-56.327.4
DEVFeatures -62.9-47.2-19.8-15.0-31.4-60.3-31.3-29.0-29.7-63.8-45.9-41.3-59.9-45.1-45.7-59.9-25.5-43.9-42.114.9
Logits -37.6-24.3 -5.5-5.2-8.8-62.3 -6.5-14.9-19.5-18.514.222.2-29.8 6.42.0-16.618.8 6.6-10.020.4
Preds -42.8-39.7-29.0-37.9-35.7-60.6-28.4-10.9-25.3-35.3 -1.0-2.4-44.2-23.4-33.1-43.1-15.4-10.6-28.815.5
DEVNFeatures, max normalization 82.277.043.563.943.179.994.996.696.772.183.182.891.487.794.997.088.294.481.616.2
Features, standardization 52.451.639.950.443.670.386.989.993.775.678.979.690.479.993.095.081.790.874.618.1
Logits, max normalization 82.675.647.868.045.079.993.494.395.468.578.679.390.084.492.696.889.696.1 81.015.1
Logits, standardization 67.553.652.856.452.372.782.584.391.570.267.871.087.573.889.194.085.593.274.814.0
Preds, max normalization 82.276.542.268.041.079.192.590.192.264.277.574.989.482.490.994.678.189.478.115.4
Preds, standardization 69.460.542.859.744.576.471.771.181.860.271.777.888.079.687.182.964.577.570.412.7
EntropySource Train 18.9 9.214.824.1 3.017.128.237.637.951.054.552.250.935.049.456.645.447.835.216.6
Source Train + Target 8.9-4.4-13.514.7-14.414.722.232.938.850.953.451.444.721.145.252.533.340.527.421.8
Source Val 3.8-4.23.517.7-2.911.520.129.138.748.851.147.248.132.446.855.834.441.029.119.4
Source Val + Target 2.7-8.3-15.813.7-16.312.417.427.338.248.850.047.842.220.343.550.426.936.124.321.9
Target 2.9-9.2-18.210.1-23.313.119.828.140.147.247.346.037.515.040.646.019.831.621.922.0
SNDFeatures,τ= 0.05 -79.6-84.4-72.6-88.7-75.0-79.9-63.8-73.8-81.6-70.6-73.2-77.1-71.1-77.2-75.0-63.0-74.5-79.2-75.6 6.2
Features,τ= 0.1 -78.3-79.6-69.7-87.4-72.7-79.3-64.9-72.9-79.6-69.0-72.3-75.3-70.5-75.1-74.8-61.2-72.0-78.1-74.0 5.9
Features,τ= 0.5 -76.0-77.0-73.1-82.5-73.7-76.3-69.9-74.8-77.5-75.1-74.8-75.7-75.5-77.4-75.1-61.0-71.8-76.0-74.6 4.2
Logits,τ= 0.05 -76.9-70.3-71.0-79.3-73.2-78.8-68.9-80.9-83.9-72.2-78.2-82.4-73.8-79.3-76.3-63.9-77.0-81.2-76.0 5.1
Logits,τ= 0.1 -75.6-67.7-71.8-76.2-72.9-77.1-71.2-78.8-84.4-73.0-77.3-81.2-72.9-79.7-77.0-62.8-77.4-78.2-75.3 4.9
Logits,τ= 0.5 -76.0-66.8-76.0-75.6-77.2-79.4-74.3-79.8-86.6-76.7-79.8-81.7-78.4-81.0-78.7-67.3-78.7-79.8-77.4 4.6
Preds,τ= 0.05 -77.9-74.2-81.2-85.1-80.8-85.7-81.5-85.7-87.0-74.6-80.4-79.6-78.0-78.4-79.0-69.5-82.8-83.0-80.2 4.4
Preds,τ= 0.1 -77.9-73.4-79.7-84.3-78.2-85.9-85.9-82.9-85.8-74.4-80.3-79.1-78.2-78.0-80.0-72.0-82.1-81.6-80.04.0
Preds,τ= 0.5 -77.4-73.0-72.8-83.7-72.8-86.3-81.0-79.9-83.0-74.5-80.3-80.4-77.9-73.8-82.1-76.8-78.5-81.0-78.64.0
Table 17: The weighted Spearman correlation of each validator/task pair for CDAN.
AD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP Mean Std
AccuracySource Train 74.679.588.569.185.244.865.873.071.649.071.771.373.278.083.063.876.672.271.710.7
Source Val 85.192.277.675.286.261.196.497.794.277.593.091.295.295.997.095.095.595.989.09.8
BNMSource Train 51.668.961.930.670.134.557.665.058.238.259.861.363.776.277.336.362.858.957.413.5
Source Train + Target 38.054.074.753.981.312.377.873.056.439.864.765.557.480.373.741.878.162.660.317.8
Source Val 60.879.060.065.373.241.989.987.877.040.263.064.275.189.585.371.491.585.572.215.1
Source Val + Target 51.772.970.769.279.937.087.184.773.340.165.465.760.784.579.353.386.879.669.014.9
Target 37.252.274.554.781.011.077.972.656.139.964.865.857.380.273.541.878.162.560.118.1
ClassAMISource + Target Features 32.746.869.226.379.531.276.274.345.648.063.968.965.982.577.857.487.870.161.318.2
Source + Target Logits 28.843.766.324.775.429.773.872.242.343.761.265.561.681.576.355.786.468.558.718.4
Target Features -32.3-41.5-23.1-47.9-26.2-37.5-63.4-13.1-56.1-63.8-59.6-60.1-55.3-48.3-24.2-53.1-34.0-57.3-44.315.3
Target Logits -31.7-38.9-19.2-48.6-24.4-32.1-65.0 -8.6-52.4-63.4-58.1-58.5-48.8-50.7-18.1-51.8-34.9-55.8-42.316.4
ClassSSSource + Target Features 19.317.643.3-11.948.5-13.227.132.015.6-7.021.420.1-8.620.131.0-2.845.322.117.818.9
Source + Target Logits 13.8-1.532.8-26.441.1-15.524.132.1 9.0-2.321.018.0-1.028.535.415.750.626.016.719.5
Target Features 23.927.342.4-6.646.5-6.023.528.5 7.5-20.214.413.5-13.217.026.3-1.742.719.315.818.9
Target Logits 19.726.330.7-5.137.2-9.530.029.3 3.5-15.315.611.2-15.626.727.410.149.821.316.318.0
DEVFeatures -64.9-82.0-16.217.347.0 7.642.748.228.3-8.8-15.8-11.5 -6.86.316.5-21.2 4.610.6 0.133.4
Logits -20.4-20.926.839.564.129.266.572.374.926.432.845.122.941.044.2 7.740.149.335.626.4
Preds -48.5-55.9-49.1-35.8-46.7-44.3 -4.6-29.3-29.2-29.861.767.8-50.356.869.7-52.076.974.2 -3.852.1
DEVNFeatures, max normalization 69.180.855.050.871.349.793.096.788.670.789.185.093.891.594.590.090.892.980.715.3
Features, standardization 73.780.761.229.176.650.486.792.384.175.078.277.792.381.885.785.786.488.577.015.4
Logits, max normalization 64.579.252.051.768.147.693.096.287.768.388.084.892.489.792.587.489.391.279.115.6
Logits, standardization 53.764.054.744.668.738.987.490.879.673.671.475.987.376.984.279.881.887.572.314.9
Preds, max normalization 63.879.150.251.165.647.393.296.688.659.073.771.291.193.292.788.194.390.477.216.7
Preds, standardization 54.171.048.137.057.136.085.691.682.047.459.059.680.186.082.876.990.081.768.117.9
EntropySource Train 47.855.353.518.857.330.959.863.955.738.255.661.949.774.871.932.163.751.952.414.1
Source Train + Target 36.844.157.712.258.030.975.868.645.938.957.460.444.776.468.142.277.159.353.017.0
Source Val 61.263.046.425.649.226.885.279.865.440.961.262.159.685.178.767.287.678.262.418.3
Source Val + Target 55.959.255.317.256.629.680.374.857.639.659.960.446.478.671.350.281.870.858.116.9
Target 34.941.255.210.856.829.175.568.245.538.857.359.143.275.867.442.076.858.952.017.3
SNDFeatures,τ= 0.05 -94.5-92.8-85.4-92.2-87.5-89.1-94.4-92.8-95.6-88.6-92.4-92.9-86.8-89.8-92.4-93.0-92.5-93.0-91.4 2.8
Features,τ= 0.1 -93.6-90.6-80.0-87.4-81.6-89.8-88.5-79.6-91.3-84.3-87.6-88.2-79.3-79.4-80.2-86.1-79.6-86.8-85.2 4.6
Features,τ= 0.5 -79.7-84.1-79.7-68.3-80.1-75.0-81.2-64.9-78.4-70.3-76.7-75.6-70.9-73.8-64.4-68.8-67.6-76.6-74.2 5.7
Logits,τ= 0.05 -92.0-91.5-89.9-93.0-91.5-89.2-97.2-97.0-97.3-90.0-94.5-95.1-88.7-92.2-96.5-95.3-97.2-94.9-93.5 2.9
Logits,τ= 0.1 -95.3-92.9-84.3-92.6-87.3-93.1-95.1-93.7-96.6-89.3-93.7-94.3-86.3-85.8-93.3-92.8-92.5-93.8-91.8 3.5
Logits,τ= 0.5 -82.1-83.2-75.5-69.5-73.7-72.5-89.1-77.5-89.3-86.0-82.6-83.1-84.2-80.1-76.7-87.7-79.2-84.0-80.9 5.6
Preds,τ= 0.05 -89.6-89.5-91.8-89.2-91.5-81.5-93.1-92.5-95.0-89.2-91.3-93.1-87.8-89.1-93.2-92.5-93.6-92.2-90.9 3.0
Preds,τ= 0.1 -95.8-93.9-91.3-97.3-91.8-95.3-97.4-97.4-97.8-90.1-94.9-95.6-89.2-94.4-97.9-96.0-98.0-95.0-94.92.7
Preds,τ= 0.5 -93.6-93.3-82.2-89.3-84.4-90.1-88.6-87.2-91.0-87.6-90.5-90.9-81.9-82.8-85.9-91.0-84.5-90.1-88.1 3.6
26Under review as submission to TMLR
Table 18: The weighted Spearman correlation of each validator/task pair for DANN.
AD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP Mean Std
AccuracySource Train 77.380.888.269.082.245.467.271.470.246.968.557.065.376.676.957.375.167.569.111.2
Source Val 88.293.777.776.582.768.094.497.197.080.691.785.192.593.095.095.388.794.388.48.0
BNMSource Train 66.375.666.628.666.721.757.866.453.043.364.647.458.371.073.637.371.946.856.515.4
Source Train + Target 40.458.272.841.476.8 3.479.563.756.342.165.541.149.078.963.039.679.644.955.319.2
Source Val 74.383.971.770.371.057.893.987.584.749.671.354.777.785.985.773.189.384.575.912.1
Source Val + Target 58.278.275.071.778.746.892.482.380.344.669.948.654.684.974.755.790.075.470.114.6
Target 37.954.371.940.476.6 2.479.563.256.242.065.339.848.778.762.639.579.444.754.619.4
ClassAMISource + Target Features 51.357.282.019.183.944.589.778.474.783.478.073.682.090.784.677.992.672.373.118.3
Source + Target Logits 33.352.177.911.779.137.287.466.360.776.166.463.473.988.178.568.190.360.765.120.1
Target Features -27.7-54.6 -2.5-23.3 -0.1-13.4-17.1-31.3 -5.4-27.5-35.6-28.6 1.61.81.3-12.6 -8.3-12.9-16.515.2
Target Logits -64.3-52.8-43.2-59.0-50.9-50.9-68.3-71.8-65.6-68.5-72.1-66.3-62.3-54.9-60.0-66.1-57.8-60.0-60.8 7.7
ClassSSSource + Target Features 34.142.434.0 6.550.7 6.510.513.213.2-11.1 7.4-12.1 9.233.623.9-2.923.017.116.617.0
Source + Target Logits 17.042.628.1-0.948.6-1.817.512.310.3-8.817.5-2.03.133.218.7-8.229.910.414.816.3
Target Features 24.738.021.1 8.934.616.9-39.1-16.7-27.2-61.8-34.0-42.6-50.8-17.8-11.2-42.0-16.2 -9.0-12.429.6
Target Logits 11.135.525.5 2.047.4 8.64.64.55.3-24.8 4.8-8.3-19.326.413.0-21.316.5 7.97.718.4
DEVFeatures -54.5-56.926.624.362.428.140.343.936.4-21.7-27.4-25.9 -7.8-1.0-13.0-26.3 -4.1-14.5 0.533.4
Logits -9.215.249.641.652.549.271.277.878.731.235.223.925.627.240.9 5.638.433.338.222.6
Preds -39.2-49.9-39.2-34.5-40.7-36.5 -2.8-5.5-12.5-22.956.340.7-47.539.064.6-51.452.267.0 -3.542.7
DEVNFeatures, max normalization 75.189.359.652.656.157.487.494.794.075.484.874.087.781.285.190.077.283.578.013.0
Features, standardization 71.487.972.123.176.251.979.088.186.573.473.567.285.169.971.980.874.471.672.414.7
Logits, max normalization 70.285.253.353.748.857.286.494.093.272.081.676.085.176.881.886.971.682.075.313.5
Logits, standardization 56.267.157.937.352.548.277.284.684.269.565.565.879.860.166.374.460.567.565.212.1
Preds, max normalization 71.487.450.054.342.156.388.394.793.462.364.951.083.885.084.887.883.385.673.716.6
Preds, standardization 60.975.245.235.337.642.481.384.982.444.451.837.671.181.773.473.385.678.163.518.2
EntropySource Train 52.229.247.8 8.341.1 9.748.356.238.131.247.636.338.360.268.021.662.528.740.316.5
Source Train + Target 33.718.252.7 5.652.327.067.053.535.732.848.630.235.768.858.829.469.828.641.617.7
Source Val 55.035.255.923.348.035.077.571.161.539.555.447.258.475.380.355.676.558.756.115.8
Source Val + Target 51.032.454.112.553.435.474.063.753.835.452.337.139.472.066.140.975.947.049.816.2
Target 29.114.849.1 3.951.426.566.352.735.533.148.328.935.268.458.229.269.428.340.518.0
SNDFeatures,τ= 0.05 -87.9-89.2-81.7-86.9-82.5-88.0-88.4-88.6-90.6-83.9-85.0-88.7-86.2-84.9-87.7-86.6-87.0-91.2-86.9 2.5
Features,τ= 0.1 -87.4-85.5-78.1-82.2-78.6-86.6-84.6-84.9-84.4-83.3-82.3-86.7-82.2-78.1-81.4-82.7-79.9-87.9-83.2 3.0
Features,τ= 0.5 -84.1-83.8-83.0-76.1-85.6-81.4-80.5-83.2-80.6-73.6-78.5-77.2-75.8-76.7-79.0-76.1-77.1-79.5-79.5 3.3
Logits,τ= 0.05 -88.8-91.4-91.4-90.8-93.1-84.0-95.9-93.2-96.3-90.4-89.7-92.9-91.6-94.0-93.5-91.5-93.6-94.2-92.0 2.7
Logits,τ= 0.1 -90.4-92.6-89.5-92.6-93.1-93.0-95.1-93.1-96.0-90.1-88.5-92.1-90.9-92.6-92.4-91.0-92.7-93.6-92.21.8
Logits,τ= 0.5 -85.0-84.0-80.6-72.6-87.4-79.7-89.3-87.8-87.2-84.9-82.0-85.2-87.1-82.7-84.3-85.9-85.0-82.6-84.1 3.7
Preds,τ= 0.05 -87.3-90.3-90.4-87.0-91.3-78.1-91.8-92.0-93.7-88.9-88.0-88.7-89.5-85.7-86.6-89.9-89.2-88.9-88.7 3.3
Preds,τ= 0.1 -90.4-93.8-90.6-96.6-92.9-92.8-94.8-93.4-96.8-90.9-91.2-95.3-91.8-94.4-94.8-92.0-93.4-94.9-93.4 1.9
Preds,τ= 0.5 -88.8-93.5-79.0-85.2-85.1-87.0-88.8-90.9-90.7-87.6-88.0-89.2-84.8-84.5-89.3-88.6-87.3-91.2-87.7 3.2
Table 19: The weighted Spearman correlation of each validator/task pair for GVB.
AD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP Mean Std
AccuracySource Train 79.176.387.572.281.066.350.953.558.951.264.054.476.470.970.158.368.265.066.910.5
Source Val 86.587.383.377.682.575.097.595.896.585.191.988.093.592.894.989.893.792.889.16.3
BNMSource Train 57.859.161.728.250.025.136.627.228.828.942.024.454.158.441.929.544.929.440.513.1
Source Train + Target 65.177.082.342.584.120.073.361.869.256.069.856.368.382.871.957.178.967.065.715.3
Source Val 64.368.870.263.265.842.979.165.669.929.146.427.962.779.161.858.778.670.461.414.9
Source Val + Target 67.581.579.962.981.237.678.864.970.148.760.744.467.583.468.758.480.270.267.013.0
Target 64.472.882.544.686.020.275.263.470.557.972.659.768.783.372.558.580.268.266.715.2
ClassAMISource + Target Features 75.282.386.831.090.232.285.769.974.772.681.975.381.085.176.367.988.070.573.716.2
Source + Target Logits 74.480.586.730.190.332.885.469.673.871.581.174.380.185.675.567.688.370.373.216.2
Target Features 8.5-34.0-10.3-13.7 3.8-16.6-51.8-45.1-62.8-48.5-48.6-37.4-27.5-50.2-48.6-59.6-50.1-62.5-36.421.5
Target Logits 9.7-33.9-10.2-13.6 1.8-15.4-52.0-45.3-62.7-48.5-48.6-37.5-27.3-50.3-48.7-59.7-50.1-61.9-36.321.5
ClassSSSource + Target Features 49.571.162.317.874.018.448.850.243.521.849.731.923.266.147.530.360.557.545.817.6
Source + Target Logits 59.871.561.617.077.629.158.256.653.640.761.849.232.570.757.542.865.662.253.815.5
Target Features 66.377.563.219.972.823.646.847.242.423.153.737.214.260.448.930.861.260.547.218.5
Target Logits 72.078.160.819.875.330.253.453.851.038.763.352.619.262.956.141.365.562.453.116.9
DEVFeatures -47.2-79.038.733.959.1-3.819.138.128.2-14.3 -8.97.81.9-10.9-11.7-42.6 -7.1-15.3 -0.833.3
Logits -23.6-24.462.544.572.317.252.758.266.921.330.327.128.150.232.811.142.340.933.926.4
Preds -45.2-45.5-39.0-42.7-42.3-53.0 -8.8-12.8-12.1-29.464.259.0-49.753.154.8-44.860.264.6 -3.946.4
DEVNFeatures, max normalization 81.584.574.553.372.159.096.192.391.976.884.278.291.588.689.884.590.185.581.911.1
Features, standardization 78.482.074.540.076.157.386.984.983.671.973.771.885.971.484.081.883.578.675.911.2
Logits, max normalization 77.580.671.953.170.856.596.091.991.473.683.675.590.687.289.082.089.385.280.311.5
Logits, standardization 66.471.271.441.876.547.388.782.282.359.571.363.682.272.481.376.683.079.872.112.2
Preds, max normalization 76.979.868.452.363.457.096.592.793.374.176.165.790.790.484.981.091.685.978.912.9
Preds, standardization 65.271.957.237.454.845.889.084.685.853.167.457.781.687.772.871.285.275.469.115.0
EntropySource Train 56.256.558.324.847.122.936.525.825.226.139.523.851.056.837.627.243.529.338.212.9
Source Train + Target 70.277.468.124.479.329.573.061.265.653.065.351.065.478.268.256.675.466.062.714.9
Source Val 61.964.765.228.759.827.566.052.661.924.644.327.455.574.357.751.771.465.753.415.7
Source Val + Target 68.378.670.223.679.328.672.158.264.746.860.144.664.478.266.156.075.366.961.215.7
Target 71.675.561.925.780.231.074.863.167.156.068.254.566.778.169.159.276.867.563.714.4
SNDFeatures,τ= 0.05 -89.2-88.4-71.8-82.7-68.3-85.1-86.5-92.5-92.1-86.4-89.7-86.2-79.8-83.7-91.4-90.2-89.2-92.5-85.9 6.6
Features,τ= 0.1 -83.0-85.0-63.7-74.8-53.3-86.2-72.3-77.8-84.2-75.8-77.7-75.7-64.9-75.5-77.4-81.1-75.3-84.4-76.0 8.2
Features,τ= 0.5 -71.5-85.0-53.8-50.9-49.4-65.2-76.0-72.2-80.4-73.7-74.7-76.8-62.3-78.2-74.0-77.7-78.2-81.5-71.210.3
Logits,τ= 0.05 -91.6-90.3-83.0-86.5-86.7-88.8-96.2-96.5-96.7-92.0-95.2-94.6-90.3-92.4-95.8-93.7-95.4-94.4-92.23.8
Logits,τ= 0.1 -91.8-90.5-79.2-88.6-81.1-94.8-92.7-96.6-96.8-90.3-94.4-92.9-84.1-88.9-95.5-93.0-93.8-95.0-91.1 5.0
Logits,τ= 0.5 -81.4-86.3-78.2-66.7-69.4-74.9-83.8-86.9-90.8-84.2-84.7-87.6-77.8-86.6-88.4-86.2-86.0-89.4-82.7 6.6
Preds,τ= 0.05 -83.6-87.8-54.2-80.0-55.9-82.8-87.7-91.3-90.9-89.4-89.6-88.8-78.7-84.6-89.9-89.6-89.2-89.1-83.510.7
Preds,τ= 0.1 -83.2-88.8-47.8-84.7-47.9-91.1-84.4-92.7-94.9-89.2-93.6-91.9-74.0-86.7-94.1-88.9-92.1-92.5-84.413.8
Preds,τ= 0.5 -82.3-88.3-48.2-74.4-53.0-80.6-80.4-86.8-85.2-87.0-86.4-85.1-72.9-82.6-87.0-84.3-85.8-87.8-79.911.2
27Under review as submission to TMLR
Table 20: The weighted Spearman correlation of each validator/task pair for IM.
AD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP Mean Std
AccuracySource Train 68.486.989.282.184.565.367.170.569.342.046.257.065.671.079.952.771.763.368.512.9
Source Val 82.493.084.683.782.975.297.197.097.875.685.186.188.692.995.694.996.895.489.17.2
BNMSource Train 71.186.883.269.081.049.165.573.745.545.239.254.670.973.473.035.466.855.063.215.1
Source Train + Target 66.986.989.579.687.236.472.582.468.854.060.970.869.082.976.146.074.968.870.713.9
Source Val 64.982.084.074.385.756.782.085.576.244.744.858.679.484.279.954.580.573.971.813.6
Source Val + Target 65.784.188.081.589.147.779.084.875.251.954.667.172.184.178.349.577.972.272.413.1
Target 66.385.889.378.986.735.567.581.669.354.063.272.068.581.875.946.373.569.270.313.7
ClassAMISource + Target Features 74.691.394.483.893.562.592.392.890.671.278.085.283.194.492.579.492.685.985.48.9
Source + Target Logits 73.490.893.083.792.262.989.791.688.566.375.983.079.294.290.075.191.784.983.79.3
Target Features -14.0-40.4-13.5 -0.1-19.7-25.4-12.0-50.9-35.1-30.2-42.3-38.9-45.6-37.6-51.0-18.8-35.6-31.1-30.114.1
Target Logits -6.5-45.9 -6.3-3.6-6.8-17.4-21.6-51.4-11.8-26.0-33.7-29.5-48.3-42.2-49.2 -4.8-38.5-19.1-25.716.7
ClassSSSource + Target Features 29.046.555.767.738.624.5-22.9-16.8 7.9-30.1-22.0 -1.9-6.811.414.9 3.0-13.5 -5.710.027.8
Source + Target Logits 12.914.337.148.817.7 7.8-22.5-19.7 -6.5-31.4-24.7-11.5 -8.56.62.6-11.1-25.3-13.8 -1.521.3
Target Features 42.354.549.668.128.033.3-50.7-23.2 -6.2-41.4-34.7 -7.3-40.8-42.9 -8.1-4.9-47.3 -6.2-2.137.7
Target Logits 26.364.032.173.610.914.7-46.3-21.7-19.9-41.6-36.6-18.1-37.4-33.1-20.5-17.4-44.7-15.2 -7.335.3
DEVFeatures -26.0 -9.527.042.551.644.726.445.444.3-3.70.62.4-15.1 1.26.3-0.40.916.314.123.1
Logits 37.657.952.053.466.165.254.065.980.339.647.557.744.948.759.035.565.270.055.611.7
Preds -11.0-19.1-33.9-36.9-39.5-35.7-33.9 -9.3-23.9-18.058.775.2-20.277.260.3-51.375.557.4 4.046.2
DEVNFeatures, max normalization 82.790.886.474.983.067.297.197.997.280.585.789.191.994.595.194.196.795.8 88.98.4
Features, standardization 74.961.282.465.579.664.192.995.189.484.384.188.089.989.889.187.391.390.683.310.0
Logits, max normalization 79.492.084.774.681.566.997.297.897.278.884.688.289.993.994.694.096.195.688.28.7
Logits, standardization 67.683.880.864.880.661.392.895.391.878.681.183.887.287.289.086.290.789.082.99.4
Preds, max normalization 80.492.283.874.678.966.896.997.597.176.183.088.088.893.593.392.896.394.987.58.9
Preds, standardization 70.485.776.955.275.856.991.094.092.067.681.688.484.387.689.485.189.192.381.311.5
EntropySource Train 62.878.173.568.374.046.164.765.846.739.537.553.359.869.565.732.565.644.158.213.5
Source Train + Target 64.474.965.379.870.764.662.867.269.548.555.267.654.571.463.252.966.255.964.17.9
Source Val 3.633.259.459.369.849.451.447.568.832.038.552.259.572.261.250.261.053.151.216.1
Source Val + Target 41.350.761.975.570.058.854.457.469.843.649.463.854.370.761.152.361.754.458.49.2
Target 57.965.447.577.263.865.655.263.369.547.555.868.447.667.359.654.861.055.560.28.0
SNDFeatures,τ= 0.05 -61.3-62.7-61.4-88.5-60.8-80.3-54.4-50.4-90.1-56.5-60.4-69.9-60.4-67.5-72.2-83.2-56.8-63.0-66.711.4
Features,τ= 0.1 -61.9-62.7-61.9-86.4-60.4-80.4-56.0-50.9-87.3-55.9-60.8-69.4-61.9-64.4-72.2-79.9-56.4-63.0-66.210.5
Features,τ= 0.5 -67.1-69.1-68.8-83.3-69.7-81.9-72.0-61.9-85.5-68.8-69.0-75.9-74.5-81.0-77.7-83.1-75.4-74.3-74.4 6.4
Logits,τ= 0.05 -63.6-64.1-62.7-88.6-61.9-81.4-54.4-51.5-91.8-59.6-61.3-73.7-62.4-72.4-76.1-84.5-57.6-64.9-68.511.5
Logits,τ= 0.1 -63.8-63.9-62.0-87.7-61.2-82.1-55.4-51.6-91.5-60.0-61.6-73.7-63.3-71.7-75.7-84.1-57.8-65.0-68.411.3
Logits,τ= 0.5 -66.9-67.3-63.1-74.2-62.8-78.9-68.0-57.5-87.0-67.2-65.7-75.4-72.4-77.5-78.8-82.6-72.8-71.8-71.7 7.4
Preds,τ= 0.05 -66.0-66.4-64.2-89.7-63.4-81.7-50.4-50.3-89.3-59.6-60.9-73.3-62.8-72.7-76.3-81.4-56.4-65.2-68.311.5
Preds,τ= 0.1 -66.3-66.7-64.6-90.8-64.0-82.7-50.7-50.2-90.8-59.6-60.9-73.5-62.9-72.6-76.4-84.1-57.0-65.5-68.911.9
Preds,τ= 0.5 -70.4-70.4-68.0-77.7-65.4-83.5-66.8-63.1-82.6-71.0-67.4-74.0-70.9-65.6-75.3-83.0-68.1-74.2-72.16.1
Table 21: The weighted Spearman correlation of each validator/task pair for MCC.
AD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP Mean Std
AccuracySource Train 78.279.388.779.387.268.354.365.360.756.467.663.173.765.876.964.573.070.270.79.4
Source Val 83.389.082.581.987.176.895.295.097.285.691.489.292.090.995.392.392.993.889.55.4
BNMSource Train 77.081.281.761.580.340.353.055.743.132.548.445.663.457.370.449.556.555.758.514.3
Source Train + Target 65.581.683.466.882.8-5.078.659.767.743.563.960.755.069.269.748.467.866.762.619.5
Source Val 79.984.279.265.883.853.788.375.175.534.556.250.774.978.880.174.680.177.671.813.7
Source Val + Target 74.883.782.472.485.832.185.270.473.842.162.057.760.472.374.758.074.273.268.614.1
Target 63.978.782.165.781.8-7.876.156.066.343.364.761.754.367.968.148.067.065.261.319.6
ClassAMISource + Target Features 76.582.588.081.788.677.690.484.685.073.482.785.380.591.687.774.091.484.483.75.5
Source + Target Logits 78.485.287.581.489.376.589.880.683.069.280.582.378.190.685.971.490.383.382.46.0
Target Features -9.3-34.0 1.27.6-26.817.1-59.3-49.1-43.5-35.2-44.3-30.1-23.9-28.7-37.5-45.9-15.7-42.2-27.720.2
Target Logits -12.2-33.0 1.94.6-28.818.2-61.1-50.4-44.5-36.4-44.3-28.6-30.0-31.4-39.5-47.2-18.9-43.9-29.220.3
ClassSSSource + Target Features 50.260.765.463.671.841.327.413.535.013.340.929.921.242.830.027.741.046.140.116.8
Source + Target Logits 54.056.559.559.373.140.628.321.940.015.747.833.226.744.927.629.346.451.742.015.0
Target Features 66.568.262.768.870.751.611.310.429.416.345.830.512.529.624.022.631.244.738.720.9
Target Logits 72.472.856.672.471.552.318.717.931.219.752.931.920.532.524.624.938.252.142.420.0
DEVFeatures -34.9-37.936.737.968.338.841.533.618.5-13.5-10.0 8.5-9.58.4-13.7-14.916.0 5.29.928.1
Logits 22.326.759.450.174.357.655.368.575.435.239.051.326.040.264.240.454.273.650.816.6
Preds -19.1-35.3-33.4-41.9-31.3-48.5-12.6 -8.3-23.5-29.884.881.9-40.973.379.3-47.785.481.5 6.353.9
DEVNFeatures, max normalization 79.186.082.265.981.165.593.892.095.380.987.285.287.285.992.088.088.090.784.88.0
Features, standardization 63.263.284.759.181.362.690.090.187.386.785.785.484.479.283.284.285.884.780.010.0
Logits, max normalization 77.886.879.266.180.065.093.992.195.380.187.284.785.584.491.785.786.790.484.08.2
Logits, standardization 69.977.479.661.080.759.492.290.990.083.483.581.583.177.384.581.383.185.380.28.7
Preds, max normalization 78.087.176.865.078.564.493.891.595.177.188.284.984.787.792.486.191.091.284.18.8
Preds, standardization 73.280.769.645.572.654.290.185.587.362.285.483.676.783.389.481.991.590.978.012.7
EntropySource Train 72.674.980.964.482.844.956.857.745.627.644.544.461.958.470.047.154.956.458.114.1
Source Train + Target 79.580.171.276.479.168.970.567.770.845.763.458.663.965.271.961.862.671.868.38.3
Source Val 21.441.966.844.977.644.265.260.370.525.050.244.568.769.975.471.866.671.757.616.6
Source Val + Target 65.463.467.266.278.754.765.863.070.141.260.454.464.764.772.565.162.571.063.97.9
Target 78.171.859.373.775.169.665.863.668.948.064.659.862.861.969.161.960.470.465.86.9
SNDFeatures,τ= 0.05 -77.2-74.6-70.6-91.1-75.7-82.3-85.6-88.9-93.9-85.1-85.7-84.6-82.8-84.3-87.1-88.3-79.8-88.8-83.7 5.9
Features,τ= 0.1 -76.4-74.1-69.0-88.4-73.4-86.6-82.4-84.7-87.2-79.9-79.4-77.7-76.7-79.9-83.3-82.1-70.8-83.7-79.8 5.4
Features,τ= 0.5 -81.4-81.9-77.9-77.5-84.4-69.7-86.6-88.9-82.7-83.6-86.6-82.5-85.2-82.3-86.0-80.4-73.2-81.0-81.8 4.7
Logits,τ= 0.05 -78.4-77.0-69.3-92.8-77.6-88.2-90.9-91.9-96.2-92.0-91.7-92.4-90.7-87.9-89.6-90.6-89.8-91.8-87.7 6.9
Logits,τ= 0.1 -78.1-76.4-66.5-90.6-74.4-89.3-87.7-90.1-93.7-89.6-88.4-89.5-87.4-82.7-86.9-88.2-79.7-88.5-84.9 6.9
Logits,τ= 0.5 -77.1-77.3-65.1-71.5-68.5-61.4-85.4-87.8-84.8-84.7-85.6-85.1-85.7-84.4-85.1-82.3-77.9-82.8-79.6 7.7
Preds,τ= 0.05 -83.1-79.8-84.3-93.9-87.4-83.8-92.2-92.2-90.8-91.4-92.7-94.6-92.0-90.9-91.3-88.6-94.4-87.2-89.54.2
Preds,τ= 0.1 -83.0-79.7-85.0-96.3-88.3-94.1-92.4-94.5-96.9-92.8-94.5-95.7-93.0-92.1-92.9-90.5-96.0-93.2-91.7 4.6
Preds,τ= 0.5 -83.6-82.1-68.5-82.5-73.1-84.7-85.7-88.2-91.1-88.0-89.4-89.6-82.2-73.6-86.1-87.7-75.9-88.3-83.4 6.3
28Under review as submission to TMLR
Table 22: The weighted Spearman correlation of each validator/task pair for MCD.
AD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP Mean Std
AccuracySource Train 83.179.780.074.280.779.582.179.163.079.473.772.687.979.482.777.188.580.979.15.6
Source Val 86.284.480.977.483.981.296.798.498.489.894.593.495.893.295.396.094.496.290.96.5
BNMSource Train 88.285.679.860.967.475.188.483.663.390.572.281.091.383.684.582.193.275.280.39.3
Source Train + Target 90.991.358.781.960.377.289.891.590.693.792.393.891.187.394.183.094.390.686.310.5
Source Val 88.984.675.675.964.171.391.492.991.992.086.789.292.892.293.392.796.193.987.08.8
Source Val + Target 91.890.366.082.861.773.590.692.792.093.491.292.791.789.794.587.595.693.487.39.7
Target 88.691.756.084.464.276.687.691.190.893.892.994.690.786.994.282.693.690.686.210.3
ClassAMISource + Target Features 86.590.445.160.657.579.974.783.776.089.683.588.691.565.987.691.889.891.979.713.4
Source + Target Logits 86.789.546.261.157.580.081.285.578.190.584.689.292.868.788.193.291.293.180.913.3
Target Features -21.2-54.2-55.9 -9.3-58.217.6-82.0-70.4-76.9-73.5-70.3-74.1-65.2-61.8-69.3-71.0-72.8-64.9-57.425.6
Target Logits -25.3-53.5-60.5 -7.9-58.4 9.3-83.5-66.8-73.4-73.4-68.8-73.3-62.8-65.1-67.6-69.6-74.0-58.7-57.423.9
ClassSSSource + Target Features 43.933.8 4.820.116.934.7-1.224.220.214.618.3 5.525.723.237.842.034.937.124.312.8
Source + Target Logits 50.645.1 2.126.4-4.639.2-2.841.016.116.828.417.1 9.418.130.148.710.539.224.017.0
Target Features 36.469.7-23.247.3-23.535.9-36.7 9.115.4-15.7 2.5-10.0-18.1-14.216.220.9-7.231.1 7.627.9
Target Logits 43.152.4-27.635.1-34.340.9-31.919.7 8.6-18.310.4-6.1-31.1 -6.38.723.4-5.629.0 6.127.1
DEVFeatures -61.7-68.4 -2.646.134.540.538.860.142.7-43.0-18.1-16.5-11.5 5.1-4.5-19.9 9.1-6.4 1.436.1
Logits -9.1-8.022.457.952.860.068.375.267.641.761.867.863.466.866.951.281.365.253.025.2
Preds -16.5-20.0 -2.5-40.2 -6.3-29.714.4 9.715.1 0.291.184.3-1.761.683.2-18.186.883.922.044.8
DEVNFeatures, max normalization 87.686.481.659.782.165.097.197.996.692.294.193.496.692.591.394.994.592.588.710.4
Features, standardization 83.178.771.052.271.963.789.388.286.485.978.879.792.880.288.290.588.782.280.610.1
Logits, max normalization 87.384.382.160.782.865.297.398.197.289.693.192.996.192.290.694.394.893.688.410.2
Logits, standardization 77.878.371.853.876.664.091.291.986.878.770.877.690.882.584.188.290.086.780.110.0
Preds, max normalization 87.184.881.360.983.464.796.798.397.791.293.793.496.492.192.294.395.395.888.910.4
Preds, standardization 83.082.179.651.777.558.792.295.691.785.291.291.793.492.390.691.495.195.385.512.0
EntropySource Train 79.871.321.255.029.871.381.982.461.387.667.475.791.083.783.681.391.174.371.718.9
Source Train + Target 78.562.9-33.573.3-26.579.968.883.085.691.183.983.988.681.288.881.187.286.769.135.8
Source Val 40.937.0-16.464.5-4.368.972.184.888.690.083.082.191.790.191.791.089.490.368.632.3
Source Val + Target 70.944.6-34.675.0-27.374.470.783.688.191.183.983.488.982.189.583.588.088.868.036.6
Target 67.458.5-35.066.0-31.877.570.481.285.691.281.983.788.979.087.980.886.886.567.036.5
SNDFeatures,τ= 0.05 -77.3-75.1-71.1-95.2-74.3-91.1-85.6-88.7-90.7-74.9-87.1-84.3-66.6-81.3-85.7-84.8-78.1-86.3-82.1 7.5
Features,τ= 0.1 -76.0-73.9-69.6-91.6-70.8-88.9-85.5-85.9-88.3-75.2-84.2-82.3-67.4-80.3-82.9-81.5-79.0-82.4-80.3 6.7
Features,τ= 0.5 -82.8-82.1-78.7-78.2-74.6-79.2-90.0-84.6-84.9-80.6-82.7-82.2-79.9-87.3-82.6-81.8-87.3-81.5-82.33.6
Logits,τ= 0.05 -78.4-75.9-72.9-94.3-76.9-91.7-86.2-89.0-89.7-75.2-86.0-84.5-67.3-80.9-85.7-84.2-78.6-85.7-82.4 6.9
Logits,τ= 0.1 -76.8-74.8-72.1-87.7-75.5-87.3-85.9-86.2-87.4-75.7-81.7-82.5-68.7-79.5-82.7-79.2-79.4-79.8-80.2 5.4
Logits,τ= 0.5 -78.7-81.9-80.1-73.9-79.7-78.9-88.9-84.8-87.9-79.8-82.5-82.3-80.3-87.5-83.7-81.8-86.0-80.5-82.2 3.7
Preds,τ= 0.05 -76.0-74.6-69.2-94.6-70.7-89.4-83.6-87.4-90.6-74.8-86.1-84.5-65.4-79.9-86.0-83.7-77.8-85.4-81.1 7.8
Preds,τ= 0.1 -75.4-73.3-67.6-96.0-68.4-89.3-83.0-87.0-91.5-74.7-86.7-85.3-64.6-78.6-86.9-82.7-77.2-86.0-80.8 8.6
Preds,τ= 0.5 -78.3-78.5-75.1-86.5-70.1-89.2-87.7-87.2-88.4-78.6-84.6-84.3-75.8-87.5-86.1-83.5-85.4-84.0-82.8 5.3
Table 23: The weighted Spearman correlation of each validator/task pair for MMD.
AD AW DA DW WA WD AC AP AR CA CP CR PA PC PR RA RC RP Mean Std
AccuracySource Train 62.467.786.471.078.165.551.962.655.442.959.253.364.664.975.755.662.665.163.69.9
Source Val 76.786.781.573.882.775.197.296.697.082.090.387.693.294.496.096.097.196.688.98.1
BNMSource Train 49.649.854.833.251.414.621.135.316.212.228.614.928.044.853.6 4.218.319.130.516.0
Source Train + Target 45.861.779.863.173.418.769.069.467.829.256.254.537.167.868.734.160.357.356.316.3
Source Val 59.165.257.156.761.438.485.182.281.018.737.124.358.668.175.560.776.078.260.219.0
Source Val + Target 50.864.373.865.672.934.781.579.078.227.450.645.142.169.071.944.069.070.660.616.1
Target 46.061.979.563.673.318.969.069.367.829.456.955.436.967.968.833.960.557.256.516.3
ClassAMISource + Target Features 63.475.789.553.583.054.285.381.383.571.883.482.575.089.486.768.988.385.177.811.0
Source + Target Logits 60.274.388.354.779.654.484.779.781.968.380.379.572.589.286.065.487.684.776.210.9
Target Features 63.678.376.554.283.052.066.167.764.335.149.471.259.064.783.455.182.469.965.312.7
Target Logits 60.475.983.255.080.650.361.475.578.143.265.372.055.762.183.155.479.679.967.612.2
ClassSSSource + Target Features 24.825.759.052.559.721.3-6.72.716.6-37.9 8.0-1.82.616.439.6 6.710.726.818.223.7
Source + Target Logits 29.133.348.255.459.524.9-2.33.811.6-33.9 9.3-1.93.118.739.3 6.86.925.318.722.6
Target Features 25.638.648.652.953.033.4-19.1-26.312.6-57.6 0.2-3.8-14.8 1.030.6-11.4-12.216.5 9.329.7
Target Logits 29.441.138.254.247.837.1-15.8-26.8 3.6-60.0 -2.6-3.0-16.6 2.025.6-15.7-12.6 7.27.429.5
DEVFeatures -30.0-28.2 5.133.128.434.838.642.411.1 4.921.319.622.335.035.7 9.343.038.520.321.2
Logits -12.2-14.556.136.561.345.530.332.336.8-7.021.816.0-6.435.128.2-3.829.522.422.722.3
Preds -46.9-52.6-59.8-48.4-62.4-52.5-37.0-43.1-35.5-50.435.937.6-62.413.555.0-63.620.047.3-22.542.1
DEVNFeatures, max normalization 72.981.672.551.957.353.095.494.694.670.780.974.287.590.591.589.894.392.580.314.3
Features, standardization 65.570.878.048.056.051.190.892.091.475.275.472.281.883.883.579.786.485.976.013.0
Logits, max normalization 68.780.567.550.761.453.495.394.694.670.180.074.986.289.990.789.994.092.779.714.3
Logits, standardization 57.065.174.246.269.347.791.692.391.468.370.967.377.180.482.778.885.588.274.113.7
Preds, max normalization 69.381.061.350.356.053.195.294.093.964.763.361.485.888.488.089.692.890.776.615.7
Preds, standardization 57.468.053.037.950.644.187.687.687.246.851.954.268.974.180.076.176.481.265.715.9
EntropySource Train 48.848.750.331.344.113.513.228.5 9.011.529.617.320.040.846.8-2.414.811.926.516.2
Source Train + Target 41.859.670.351.067.842.160.965.858.932.752.349.639.665.066.438.259.960.154.611.2
Source Val 52.465.757.646.157.932.770.671.170.717.738.826.553.366.871.655.469.674.655.516.6
Source Val + Target 50.963.870.850.568.040.365.068.465.131.250.245.842.365.868.042.963.166.456.611.9
Target 41.859.767.151.467.243.361.165.758.833.752.950.439.465.266.538.360.260.254.610.8
SNDFeatures,τ= 0.05 -89.3-80.8-74.0-72.3-79.0-70.5-77.4-84.7-80.2-88.0-79.2-74.2-81.0-69.6-69.8-88.9-77.8-87.6-79.1 6.4
Features,τ= 0.1 -80.3-59.3-61.6-50.2-51.3-65.5-67.0-73.1-57.1-83.1-57.8-59.5-57.1-51.8-40.9-69.8-61.5-59.7-61.510.2
Features,τ= 0.5 -36.4-35.4-46.3 -2.0-48.2 -1.1-20.6-61.8-46.5-47.7-36.2-22.7 -1.14.4-16.5-16.5 -3.2-43.8-26.820.0
Logits,τ= 0.05 -93.3-81.4-84.2-70.2-91.1-69.4-94.2-94.1-95.7-94.4-94.0-94.1-96.5-95.0-95.4-96.5-96.5-97.1-90.7 8.4
Logits,τ= 0.1 -95.2-88.1-77.5-84.3-86.3-92.1-89.6-93.5-90.7-94.1-91.3-92.8-92.6-87.7-89.2-92.6-91.2-95.9-90.2 4.3
Logits,τ= 0.5 -66.9-55.3-58.2-17.6-56.9-33.0-73.6-77.8-63.4-84.8-55.6-64.5-72.5-66.7-52.1-77.4-67.2-64.0-61.515.6
Preds,τ= 0.05 -90.7-72.1-82.6-66.0-86.7-56.9-72.5-81.0-77.9-85.9-72.5-71.9-82.5-66.3-72.6-75.3-74.8-71.8-75.6 8.1
Preds,τ= 0.1 -97.0-92.1-84.6-95.0-91.1-96.8-93.0-95.2-96.9-94.6-98.0-96.9-96.6-96.0-98.3-97.7-97.1-98.7-95.33.3
Preds,τ= 0.5 -88.1-88.2-43.4-63.2-42.2-71.5-55.6-81.8-68.4-87.4-80.6-71.6-65.3-60.7-70.5-79.2-67.7-79.9-70.313.4
29Under review as submission to TMLR
G.2 Weighted Spearman Correlation for MNIST
Table 24: The weighted Spearman correlation for the MNIST →MNISTM task, using the checkpoints of all
algorithms simultaneously.
MM
AccuracySource Train 9.4
Source Val -7.1
BNMSource Train 3.5
Source Train + Target 55.7
Source Val 2.5
Source Val + Target 52.8
Target 56.1
ClassAMISource + Target Features -29.4
Source + Target Logits -25.8
Target Features 2.2
Target Logits -21.5
ClassSSSource + Target Features -68.1
Source + Target Logits -66.1
Target Features -60.5
Target Logits -53.8
DEVFeatures -11.0
Logits -5.1
Preds -24.0
DEVNFeatures, max normalization -30.6
Features, standardization -14.0
Logits, max normalization -28.9
Logits, standardization -14.2
Preds, max normalization -45.2
Preds, standardization -38.7
EntropySource Train -4.1
Source Train + Target -35.6
Source Val -5.8
Source Val + Target -36.6
Target -42.2
SNDFeatures,τ= 0.05 -63.7
Features,τ= 0.1 -62.9
Features,τ= 0.5 -69.3
Logits,τ= 0.05 -67.4
Logits,τ= 0.1 -67.7
Logits,τ= 0.5 -72.8
Preds,τ= 0.05 -67.6
Preds,τ= 0.1 -66.3
Preds,τ= 0.5 -68.4
30Under review as submission to TMLR
Table 25: The weighted Spearman correlation of each validator/algorithm pair, for the MNIST →MNISTM
task.
ATDOC BNM BSP CDAN DANN GVB IM MCC MCD MMD Mean Std
AccuracySource Train -7.534.8-1.8-12.4 6.217.821.216.5 -8.027.6 9.415.6
Source Val -8.134.2-6.4 -4.4 -4.611.824.3 2.4-24.1 30.4 5.518.0
BNMSource Train -9.535.938.8 -4.7 14.816.944.7 8.1-5.528.216.818.7
Source Train + Target 81.2 56.472.8 36.2 61.730.648.250.792.5 23.955.421.0
Source Val 12.650.752.2 -0.9 11.314.865.0-27.7 7.425.721.126.6
Source Val + Target 81.156.774.8 35.1 61.126.250.851.8 92.3 22.855.321.9
Target 80.356.369.4 40.262.535.541.948.992.3 25.355.320.0
ClassAMISource + Target Features -21.6 33.5-78.8 43.6 58.315.856.3-32.9-58.2 7.72.445.8
Source + Target Logits -0.837.4-78.060.3 57.719.658.3-42.6-56.8 -10.7 4.448.2
Target Features 45.7-19.2-69.6 -43.4 21.5-52.9-34.8-16.6 4.723.7-14.135.4
Target Logits 25.123.1-72.4 -53.6 -67.5-56.7 3.0-30.4-49.1 7.9-27.136.2
ClassSSSource + Target Features -1.9-67.1-76.1 -59.2 -38.5-39.5-59.9-56.8-36.5 2.5-43.325.0
Source + Target Logits -8.7-73.7-77.1 -41.1 -47.6-31.5-62.4-66.0-28.6 33.3-40.332.1
Target Features -11.6-55.9-76.7 -59.3 -35.8-43.3-56.7-60.0-46.0 -10.6-45.620.2
Target Logits -20.4-67.1-80.2 -41.3 -36.8-40.7-60.5-61.4-53.4 27.7-43.428.8
DEVFeatures 22.8-52.6-10.5 9.5-12.9-13.1-38.8 -7.7-47.9 9.1-14.224.0
Logits 9.5-18.3-16.1 1.6 -4.4 8.120.2-3.4-73.2 8.1-6.824.8
Preds 18.2-8.222.9 11.7 22.515.3-9.6-20.5-45.6 15.7 2.221.4
DEVNFeatures, max normalization -0.9-13.3 5.4 -5.0-10.1-14.7-26.3-13.1-11.8 9.3-8.110.0
Features, standardization 32.3-13.927.3 11.1 -7.6-16.9-24.5-12.5-23.4 18.4 -1.020.2
Logits, max normalization 6.2-16.613.7 -5.9 -7.3-16.9-28.7-12.6-12.9 7.7-7.312.4
Logits, standardization 13.4-19.1 2.5 7.8 9.7-11.0-20.9 3.0-42.1 6.6-5.016.8
Preds, max normalization -17.4 -9.4-1.2 -3.1-13.5 -7.1-26.4-13.8-24.0 11.8-10.410.8
Preds, standardization -29.3-51.0 -6.5 22.0 -2.0-4.4-36.5 -9.1-45.2 5.8-15.622.5
EntropySource Train -5.835.945.8 -30.1 -22.9 16.345.8 7.5-5.329.111.626.1
Source Train + Target -47.7-18.165.4 -4.2 10.412.6-6.621.6-66.6 16.1 -1.735.1
Source Val 14.152.857.9 -29.3 -24.0 14.764.6-32.3 6.827.515.334.2
Source Val + Target -47.6-19.564.9 -3.4 11.213.2-7.816.5-69.8 15.9 -2.635.4
Target -46.1-46.357.0 -0.5 4.220.1-47.0 14.4-84.2 16.3-11.240.6
SNDFeatures,τ= 0.05 -34.1-41.9-73.8 -78.3 -62.9-80.5-42.6-66.5-22.9 39.0-46.434.1
Features,τ= 0.1 -36.5-40.7-73.8 -82.3 -60.6-80.0-43.5-62.0-25.139.8-46.534.1
Features,τ= 0.5 -27.4-68.7-76.4 -82.4 -65.1-80.3-69.7-58.3-37.2 37.9-52.834.7
Logits,τ= 0.05 -12.8-56.1-75.1 -75.2 -69.2-84.6-51.9-90.4-13.7 -54.9-58.425.6
Logits,τ= 0.1 -16.8-51.8-75.4 -84.5 -69.1-84.4-49.0-88.7-15.7 -60.1-59.525.2
Logits,τ= 0.5 -26.6-52.8-76.3 -81.0 -71.0-78.4-60.5-80.1-25.7 -48.2-60.120.1
Preds,τ= 0.05 -5.0-61.5-75.9 -80.2 -75.5-87.6-52.7-85.6-36.7 -43.2-60.424.9
Preds,τ= 0.1 -7.6-60.4-77.1 -85.0 -76.3-85.6-52.0-85.9-37.3 -72.6-64.024.2
Preds,τ= 0.5 -16.7-56.9-80.6 -82.6 -76.4-83.6-51.7-85.5-43.2 -40.1-61.722.4
31Under review as submission to TMLR
H Summary of UDA Algorithms
The goal of unsupervised domain adaptation (UDA) is to adapt a model trained on labeled source data, for use on
unlabeled target data. Applications of UDA include:
•semantic segmentation (Toldo et al., 2020)
•object detection (Oza et al., 2021)
•natural language processing (Ramponi & Plank, 2020)
There are also other types of domain adaptation, including:
•semi-supervised (Saito et al., 2019)
•multi-source (Peng et al., 2019)
•partial (Panareda Busto & Gall, 2017; Saito et al., 2018b; Cao et al., 2018)
•universal (You et al., 2019a)
•source-free (Liang et al., 2020)
In this paper, we focus on UDA for image classification, because it is well-studied and often used as a foundation for
other domain adaptation subfields.
Here we provide a summary of UDA algorithms by category:
•Adversarial methods use a GAN where the generator outputs feature vectors. The discriminator’s goal is to
correctly classify features as coming from the source or target domain, while the generator tries to minimize
the discriminator’s accuracy. Examples:
–DANN (Ganin et al., 2016)
–Domain Confusion (Tzeng et al., 2015)
–ADDA (Tzeng et al., 2017)
–CDAN (Long et al., 2017a)
–VADA (Shu et al., 2018)
•Feature distance losses encourage source and target features to have similar distributions. Examples:
–MMD (Long et al., 2015)
–CORAL (Sun et al., 2016)
–JMMD (Long et al., 2017b)
•Maximum classifier discrepancy methods use a generator and multiple classifiers in an adversarial setup.
The classifiers’ goal is to maximize the difference between their prediction vectors (i.e. after softmax) for the
target domain data, while the generator’s goal is to minimize this discrepancy. Examples:
–MCD (Saito et al., 2018a)
–SWD (Lee et al., 2019)
–STAR (Lu et al., 2020)
•Information maximization methods use the entropy or mutual information of prediction vectors. Examples:
–ITL (Shi & Sha, 2012)
–MCC (Jin et al., 2020)
–SENTRY (Prabhu et al., 2021)
•SVD losses apply singular value decomposition to the source and/or target features. Examples:
–BSP (Chen et al., 2019)
–BNM (Cui et al., 2020a)
•Image generation methods use a decoder model to generate source/target -like images from feature vectors,
usually as part of of an adversarial method. Examples:
–DRCN (Ghifary et al., 2016)
–GTA (Sankaranarayanan et al., 2018)
32Under review as submission to TMLR
•Pseudo-labeling methods generate labels for the unlabeled target-domain data, to transform the problem
from unsupervised to supervised. This is also known as self-supervised learning. Examples:
–ATDA (Saito et al., 2017)
–ATDOC (Liang et al., 2021)
•Mixup augmentations create training data and features that are a blend between source and target
domains. Examples:
–DM-ADA (Xu et al., 2020)
–DMRL (Wu et al., 2020)
•Other notable methods that are more difficult to categorize include:
–RTN (Long et al., 2016)
–AFN (Xu et al., 2019)
–DSBN (Chang et al., 2019)
–SymNets (Zhang et al., 2019)
–GVB (Cui et al., 2020b)
33